{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ColabGettingStarted.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hogo56/BertQA/blob/master/ColabGettingStarted.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Js7aj8RDhSjz",
        "colab_type": "text"
      },
      "source": [
        "# Colab / Kaggle Getting Started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SA1MAb09BlQB",
        "colab_type": "text"
      },
      "source": [
        "I prefer to do my primary development in a Colab virtual machine but, some competitions require your kernel to run on Kaggle for scoring. You can start with this notebook and add your own project code which should run in either location if you use the directory variables for file locations and correctly configure data and user libraries in Kaggle.<br>\n",
        "If you run into problems or have suggestions I'd love to hear from you."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93AfEfEABMXB",
        "colab_type": "text"
      },
      "source": [
        "## Explanation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKO_K9DlBuyk",
        "colab_type": "text"
      },
      "source": [
        "### Data & Directories\n",
        "There are a couple of differences between Kaggle and Colab.<p>\n",
        "**Kaggle** - you create persistent links in your kernel to datasets and utility scripts that your notebook can access. If you have private data you can create your own datasets at Kaggle. You can put utiliity scripts (user libraries) in a dataset and copy them to a lib directory on Kaggle at runtime. Internet access may or may not be allowed when scoring a Kaggle notebook.<br>\n",
        "**Colab** - nothing is persistent. You have to (and can) download data and user library scripts to your VM each time you run it. Kaggle provides an API that makes fetching data and scripts easy.<p>\n",
        "\n",
        "Also, parts of the Kaggle directory structure are read-only so file locations are different. (eg. ./lib and ./working/lib)<p> \n",
        "\n",
        "Finally, if you happen to like to SSH into your VM to watch the process run or to edit files and mung stuff around, there is code at the bottom of this Notebook that will allow you to do that in Colab. This code needs to be deleted from your notebook before submitting a notebook to competition.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7d1DROZB3cF",
        "colab_type": "text"
      },
      "source": [
        "### User Libraries\n",
        "**Colab** - you have a file system you can write to and if you need libraries you download them from somewhere. (eg. Google Dirve, Kaggle, GitHub)<br>\n",
        "**Kaggle** - you have two options (internet connections are disabled during competition scoring):<p>\n",
        "   * Add custom libraries to a dataset and include the dataset in your Kaggle kernel.<br>\n",
        "   * Create a new kernel as a script, set it as a \"Utility Script\", add the kernel-script as a utility script in your competition kernel. The sctript will be linked to your kernel in the/kaggle/usr/lib directory (see: https://www.kaggle.com/product-feedback/91185 for more information) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOQz9QFOB5EB",
        "colab_type": "text"
      },
      "source": [
        "### Switching between Colab & Kaggle\n",
        "One way of moving your script from Colab to Kaggle to run is:<br>\n",
        "   * delete all cells from your Kaggle competition notebook<br>\n",
        "   * download the .ipynb from Colab<br>\n",
        "   * upload it into the blank Kaggle notebook.<br>\n",
        "   * delete the cells near the bottom of the notebook that need to be deleted when running on Kaggle<br>\n",
        "   * update any script parameters (eg. verbose)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dMWt8F8B9k2",
        "colab_type": "text"
      },
      "source": [
        "### Drectory Structure (Notebook)\n",
        "\n",
        "* Kaggle &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <em>(cwd = /kaggle/working/)</em><br>\n",
        "  {datadir} = /kaggle/input/<br>\n",
        "  {outdir} = /kaggle/working/<br>\n",
        "* Colab &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <em>(cwd = /content/)</em><br>\n",
        "  {datadir} = /content/data/<br>\n",
        "  {outdir} = /content/output/<br>\n",
        "\n",
        "#### - Required Libraries\n",
        "**Kaggle** will be copied from a data directory<br>\n",
        "**Colab** will be copied from a gDrive directory<br>\n",
        "   * project_lib.py\n",
        "\n",
        "#### - Inputs (competition data)\n",
        "   * {datadir}/{competition}/ (from: https://www.kaggle.com/_path_/)\n",
        "\n",
        "#### - Required Data (additional packages)\n",
        "   * {datadir}/kaggle-dataset (from https://www.kaggle.com/_user_/_dataset_/)\n",
        "\n",
        "#### - Outputs\n",
        "   * {outdir}/predictions.json\n",
        "   * {outdir}/submission.csv<br>\n",
        "   * {outdir}/eval.tf_record<br>\n",
        "   * {outdir}/.ipynb_checkpoints/<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftZ8SR0WC5Nj",
        "colab_type": "text"
      },
      "source": [
        "### Drectory Structure (Google Drive)\n",
        "Because Google Colab virtual machines are not persistent I am using a link to your Google Drive.<br>\n",
        "The following is the file structure<p>\n",
        "\n",
        "/My Drive/colab/ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <em>(this directory should be private)</em><br>\n",
        "/My Drive/colab/{gprojdir}/output/<br>\n",
        "/My Drive/colab/{gprojdir}/kaggle.json &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <em>(your personal Kaggle auth file)</em><br>\n",
        "/My Drive/{gprojdir}/ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <em>(this directory should be shared between teams)</em><br>\n",
        "/My Drive/{gprojdir}/lib/{gnotedir}/ &nbsp; &nbsp; &nbsp; &nbsp;  &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<em>(libraries for this Notebook)</em><br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiQT_p1OCN9J",
        "colab_type": "text"
      },
      "source": [
        "### - Notes\n",
        "Put notes about your Notebook here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jCycAU1aL99h"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### - Credits / Ancestry\n",
        "If your notebook is a fork or combination of other notebooks here you should provide links so other people can look at where you built your current work from.<p>\n",
        "This notebook is a fork of [mmmarchetti's notebook](https://www.kaggle.com/mmmarchetti/tensorflow-2-0-bert-yes-no-answers) which was a fork of [prokaj's - bert joint baseline notebook](https://www.kaggle.com/prokaj/bert-joint-baseline-notebook/notebook).<br>\n",
        "mmmarchetti made some modifications to slightly improve the code and get the YES / NO answers and leave the unknowns blank."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNoEkLc0CXXu",
        "colab_type": "text"
      },
      "source": [
        "## Notebook Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNni7Dc1NzVe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CompSubmission = False                       # Set to True if submitting to Competition\n",
        "from pathlib import Path\n",
        "## Reset kernel without removing downloaded data files and libs\n",
        "if True and not Path('/kaggle').exists():    # the rm confirmation messages don't show up right on Kaggle so False there\n",
        "    %reset\n",
        "    from pathlib import Path                 # have to reimport after reset \n",
        "    for p in ['/content/output/', '/kaggle/working/']:\n",
        "        if Path(p).exists() and sum(1 for _ in Path(p).iterdir()) > 1:    # are there files in dir?\n",
        "            print(\"\\nWARNING: Files found in output directory.\")\n",
        "            print(\"Removing previous output files is not reversable.\")\n",
        "            ! rm -i \"{p}\"*"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaUs7DxSKDVG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Required for all\n",
        "import os\n",
        "\n",
        "class ExecutionStop(Exception):             # Custom Error Handler\n",
        "    def __init__(self, value): self.value=value\n",
        "    def __str__(self): return(str(self.value))\n",
        "\n",
        "def list_files(startpath):                  #  Show files\n",
        "    for root, dirs, files in os.walk(startpath):\n",
        "        level = root.replace(startpath, '').count(os.sep)\n",
        "        indent = ' ' * 4 * (level)\n",
        "        print('{}{}/'.format(indent, os.path.basename(root)))\n",
        "        subindent = ' ' * 4 * (level + 1)\n",
        "        for f in files:\n",
        "            print('{}{}'.format(subindent, f))\n",
        "# raise ExecutionStop(\"Message\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F30YID4j_khp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Set file locations    (these variables are not implemented in the FLAGS code yet)\n",
        "import os, sys\n",
        "from pathlib import Path\n",
        "\n",
        "## Config Variables\n",
        "verbose = True if not CompSubmission else False  # Turn this off to supress some of the \"fyi\" output\n",
        "competition = 'tensorflow2-question-answering'\n",
        "train_file = 'simplified-nq-train.jsonl'\n",
        "test_file = 'simplified-nq-test.jsonl'\n",
        "gprojdir = 'bertqa'                 # The project directory on Drive for this competition\n",
        "gnotedir = 'BERTjoint_yes_no'       # Subdir on Drive for files specific to this notebook\n",
        "DownloadBigFiles = True             # Files will not download if already on drive\n",
        "RunSmallConfig = False              # Reduce the bert_config.json values\n",
        "\n",
        "if Path('/content').exists():\n",
        "    print(\"Detected running on Colab\")\n",
        "    kernel = 'Colab'\n",
        "    basedir = '/content'\n",
        "    libdir = f\"{basedir}/lib\"\n",
        "    datadir = f\"{basedir}/data\"\n",
        "    outdir = f\"{basedir}/output\"    # will be symlinked to a user's private gdrive for persistence\n",
        "elif Path('/kaggle').exists():\n",
        "    print(\"Detected running on Kaggle\")\n",
        "    kernel = 'Kaggle'\n",
        "    basedir = '/kaggle'\n",
        "    libdir = f\"{basedir}/working/lib\"      # this has to be in a writable location\n",
        "    datadir = f\"{basedir}/input\"    # this may need to be '../input' for scoring\n",
        "    outdir = f\"{basedir}/working\"   # this may need to be '.' for scoring# BertQA\n",
        "else:\n",
        "    raise ExecutionStop(\"Cannot continue without determining file locations\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNzAuLZDzG_R",
        "colab_type": "text"
      },
      "source": [
        "# ============= Machine Spinup ============="
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKPv6ALYbXiY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! zdump PST\n",
        "if verbose:\n",
        "    ! pwd\n",
        "    list_files(basedir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aheaRzVE6fs1",
        "colab_type": "text"
      },
      "source": [
        "## -- Setup --"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gixU6_gv678n",
        "colab_type": "text"
      },
      "source": [
        "### Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auXx45x70Qcs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## File link to Google Drive\n",
        "if kernel == 'Colab':\n",
        "    from google.colab import drive\n",
        "    drive.mount(f\"{basedir}/gdrive\", force_remount=False)   # true to reread drive\n",
        "\n",
        "    # Create a shorter shared directory name and avoid having to deal with the space\n",
        "    if Path(f\"{basedir}/{gprojdir}\").is_symlink():\n",
        "        ! rm \"{basedir}/{gprojdir}\"\n",
        "    ! ln -s \"{basedir}/gdrive/My Drive/{gprojdir}\" \"{basedir}/{gprojdir}\"\n",
        "    if not Path(f\"{basedir}/{gprojdir}\").exists():\n",
        "        raise ExecutionStop(\"You cannot continue without gdirve project dir symlink\")\n",
        "\n",
        "    ## If you do not want output to be written to your Google Drive set block False\n",
        "    if True:\n",
        "        if Path(f\"{outdir}\").is_symlink():\n",
        "            ! rm \"{outdir}\"\n",
        "        ! ln -s \"{basedir}/gdrive/My Drive/colab/{gprojdir}/output\" \"{outdir}\"\n",
        "        if not Path(outdir).exists():\n",
        "            raise ExecutionStop(\"You cannot continue without gdrive output symlink\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ga-sQOkk1YvA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if False:\n",
        "    ## Flush and unmount Google Drive\n",
        "    # You probably won't do this but if you want to at some point click the play button\n",
        "    drive.flush_and_unmount()\n",
        "\n",
        "## Install the large file downloader for Google Drive if needed (Colab already has it installed)\n",
        "#  This works from bash or Python. Already installed in Colab by default.\n",
        "if False:\n",
        "    ! pip install gdown"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8BLJAW95ih-",
        "colab_type": "text"
      },
      "source": [
        "### Kaggle API\n",
        "<Details>You will need Kaggle API token to link the Colab instance to your Kaggle account to get data, etc.<br>\n",
        "Go to: https://www.kaggle.com/yourID/account and click on the \"Create New API Token: button to get a file named kaggle.json.<p>You can put your kaggle.json file in your google drive at My Drive/colab/kaggle.json.<br>\n",
        "Alternately, you can store it on your local machine and the script will ask you to upload it.</Details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lc3IYPUg17c8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Link to Kaggle\n",
        "if kernel == 'Colab':\n",
        "    from google.colab import files\n",
        "\n",
        "    if Path(f\"{basedir}/gdrive/My Drive/colab/kaggle.json\").exists():\n",
        "        # if there is a kaggle.json file in gdrive use it\n",
        "        os.environ['KAGGLE_CONFIG_DIR'] = f\"{basedir}/gdrive/My Drive/colab/\"\n",
        "        ! ls -l \"{basedir}/gdrive/My Drive/colab/kaggle.json\"\n",
        "        import kaggle\n",
        "    else:\n",
        "        # Have user upload file\n",
        "        print('Upload kaggle.json.')\n",
        "        # The files.upload() command is failing sporatically with:\n",
        "        #   TypeError: Cannot read property '_uploadFiles' of undefined (just run this cell again)\n",
        "        ! rm \"{basedir}/kaggle.json\"  2> /dev/null\n",
        "        files.upload()\n",
        "        ! chmnod 600 kaggle.json\n",
        "        os.environ['KAGGLE_CONFIG_DIR'] = f\"{basedir}/\"\n",
        "        ! ls -l \"{basedir}/kaggle.json\"\n",
        "        import kaggle\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0k60Je4YEQa",
        "colab_type": "text"
      },
      "source": [
        "## -- Main System Config --\n",
        "<Details><Summary>Global Config</Summary>\n",
        "Put any global system configuration here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72Ermuc261_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if kernel == \"Colab\":\n",
        "    if Path(f\"{basedir}/sample_data\").exists():\n",
        "        !rm -rf \"{basedir}/sample_data\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNKoTizrh9RG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash -s \"{libdir}\" \"{datadir}\" \"{outdir}\"\n",
        "# make directories if not already exist\n",
        "[ -d \"$1\" ] || mkdir -p \"$1\"        # {libdir}\n",
        "[ -d \"$2\" ] || mkdir -p \"$2\"        # {datadir}\n",
        "[ -d \"$3\" ] || mkdir -p \"$3\"        # {outdir}\n",
        "zdump PST"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdjitRnQynwk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "if not libdir in sys.path:          # don't add multiple times\n",
        "    sys.path.append(libdir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Pq9DBlECVVvY",
        "colab": {}
      },
      "source": [
        "if verbose:\n",
        "    !pwd\n",
        "    !ls -l\n",
        "    print()\n",
        "    !printenv |grep -E 'KAGGLE|PYTHON'\n",
        "    print(\"\\n[nsys.path]\", *(sys.path), sep='\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "javRwDS6zhOC",
        "colab_type": "text"
      },
      "source": [
        "# =========== Project Specific Stuff ==========="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JFQgZRN2PaEE"
      },
      "source": [
        "## -- Project Setup --"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAqCNh4y8DJz",
        "colab_type": "text"
      },
      "source": [
        "### Download Dataset and Support Files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGGM0EVmM24H",
        "colab_type": "text"
      },
      "source": [
        "Kaggle Competition Files<br>\n",
        "Here is an example of downlaoding and unpacking competition data. If the competition set has different files you will need to adjust."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5XcpPkyLBzaA",
        "colab": {}
      },
      "source": [
        "## Competition Dataset  (5GB zipped)\n",
        "if DownloadBigFiles and kernel == 'Colab':\n",
        "    if not Path(f\"{datadir}/compdata.flag\").exists():      ## Don't download again if exists\n",
        "        if verbose:\n",
        "            ! kaggle competitions list\n",
        "            print()\n",
        "        print(\"Downloading Competition Data\\n\")\n",
        "        ! kaggle competitions download -c \"{competition}\" -p \"{datadir}\"\n",
        "        ! mkdir -p \"{datadir}/{competition}/\"\n",
        "        ! mv \"{datadir}/sample_submission.csv\"  \"{datadir}/{competition}\"\n",
        "        ! unzip \"{datadir}/{train_file}.zip\" -d \"{datadir}/{competition}\"\n",
        "        ! rm \"{datadir}/{train_file}.zip\"\n",
        "        ! unzip \"{datadir}/{test_file}.zip\" -d \"{datadir}/{competition}\"\n",
        "        ! rm \"{datadir}/{test_file}.zip\"\n",
        "        ! touch \"{datadir}/compdata.flag\"\n",
        "    else:\n",
        "        print(\"Competition Data already exists. Not downloading.\\n\")\n",
        "        !ls -l \"{datadir}/{competition}\"/*\n",
        "else:\n",
        "    print(\" For Kaggle, make sure you download a copy of the competition data into your kernel\")\n",
        "    ! ls -l \"{datadir}/{competition}\"/*\n",
        "\n",
        "public_dataset = os.path.getsize(f\"{datadir}/{competition}/{test_file}\")<20_000_000\n",
        "private_dataset = os.path.getsize(f\"{datadir}/{competition}/{test_file}\")>=20_000_000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZhNV3PJHOEL",
        "colab_type": "text"
      },
      "source": [
        "Additional Data Files<br>\n",
        "Here is an example of downlaoding and unpacking additional data files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s207mPqAHDVw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get BERTjoint model files (this a copy of the prokaj file from my Google Drive)\n",
        "if DownloadBigFiles and kernel == 'Colab':\n",
        "    if not Path(f\"{datadir}/bertfiles.flag\").exists():      ## Don't download again if exists\n",
        "        print(\"Downloading BERT-joint Model\\n\")\n",
        "        ! mkdir -p \"{datadir}/bert-joint-baseline/\"\n",
        "        filestoget = \"bert_config* model_cpkt* nq-test* vocab*\"\n",
        "        ! kaggle datasets download -d prokaj/bert-joint-baseline -p \"{datadir}\"\n",
        "        ! unzip \"{datadir}/bert-joint-baseline.zip\" {filestoget} -d \"{datadir}/bert-joint-baseline/\"\n",
        "        ! rm \"{datadir}/bert-joint-baseline.zip\"\n",
        "        if Path(f\"{datadir}/bert-joint-baseline-output.npz\").exists():\n",
        "            ! rm \"{datadir}/bert-joint-baseline-output.npz\" # if kaggle downloaded this delete it\n",
        "        if verbose:\n",
        "            ! ls -l \"{datadir}/bert-joint-baseline/\"\n",
        "        ! touch \"{datadir}/bertfiles.flag\"\n",
        "    else:\n",
        "        print(\"BERT-joint Files already exists. Not downloading.\\n\")\n",
        "        ! ls -l \"{datadir}/bert-joint-baseline/\"\n",
        "else:\n",
        "    print(\"For Kaggle, make sure you download a copy of prokaj's bert-joint-baseline to your kernel\")\n",
        "    ! ls -l \"{datadir}/bert-joint-baseline/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bNPxSmhMJC5c"
      },
      "source": [
        "### Library Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yr69yF8fepTA",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "## Copy lib files from Google Drive\n",
        "if kernel == 'Colab':\n",
        "    # each Notebook has its own set of lib files in the shared Google Drive folder\n",
        "    ! cp -a \"{basedir}/{gprojdir}/lib/{gnotedir}/\"* \"{libdir}\"\n",
        "if kernel == 'Kaggle':\n",
        "    ! cp \"{datadir}/bert-joint-baseline\"/*.py \"{libdir}\"\n",
        "if verbose:\n",
        "    ! ls -l \"{libdir}\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhpBRp11R0jv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Load Libraries\n",
        "import os, sys, importlib\n",
        "\n",
        "if kernel == \"Colab\":\n",
        "    #magic to make colab path to Tensorflow V2 on Colab\n",
        "    %tensorflow_version 2.x \n",
        "\n",
        "import tensorflow as tf\n",
        "print(\"TensofFlow\", tf.__version__)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import collections\n",
        "\n",
        "import bert_utils\n",
        "import modeling\n",
        "import tokenization\n",
        "\n",
        "import json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsBNWHa3p6CL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## uncomment and use this cell to reimport libs you have updated\n",
        "# importlibe.reload(bert_utils)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJC4o-hkuIfO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! zdump PST\n",
        "! pwd\n",
        "if verbose:\n",
        "    list_files(basedir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7niWvRW-R5C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# raise ExecutionStop(\"Execution stopped\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsnKczo07ygW",
        "colab_type": "text"
      },
      "source": [
        "## -- Code Implementation For Your Project --"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhcWhldD17Q4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! zdump PST"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beaF_fYhtUxn",
        "colab_type": "text"
      },
      "source": [
        "### Support Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4hOx_86tTFI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Sample(tf.keras.layers.Layer):\n",
        "    def __init__(self,\n",
        "                 output_size,\n",
        "                 kernel_initializer=None,\n",
        "                 bias_initializer=\"zeros\",\n",
        "                **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "\n",
        "def mk_model(config):\n",
        "    return          # tf.keras.Model()    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDnBbvUCuHI-",
        "colab_type": "text"
      },
      "source": [
        "### Setting the Flags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0D_JoNumuOPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DummyObject:\n",
        "    def __init__(self,**kwargs):\n",
        "        self.__dict__.update(kwargs)\n",
        "\n",
        "FLAGS=DummyObject(skip_nested_contexts=True,\n",
        "                 max_position=50,\n",
        "                 max_contexts=48,\n",
        "                 max_query_length=64,\n",
        "                 max_seq_length=512,\n",
        "                 doc_stride=128,\n",
        "                 include_unknowns=-1.0,\n",
        "                 n_best_size=20,\n",
        "                 max_answer_length=30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEnip0KLtx--",
        "colab_type": "text"
      },
      "source": [
        "### Create Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNUN2aCD0sG5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"\\nGPU Memory\\n\")\n",
        "!nvidia-smi --query-gpu=utilization.memory,memory.total,memory.free,memory.used --format=csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTkY-he7qRbj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## grab a config file  (make sure and use variables for file locagtions)\n",
        "with open(f\"{datadir}/some_path/config.json\", 'r') as f:\n",
        "    config = json.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzVE2wQGt2Au",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if RunSmallConfig:          # it seems these values won't work\n",
        "    small_config = config.copy()\n",
        "    small_config['value_to_override']=16                # was 30522\n",
        "    model = mk_model(small_config)\n",
        "    print(json.dumps(small_config, indent=4))\n",
        "else:\n",
        "    model= mk_model(config)\n",
        "    print(json.dumps(config, indent=4))\n",
        "\n",
        "model.summary()\n",
        "print(\"\\nGPU Memory\\n\")\n",
        "!nvidia-smi --query-gpu=utilization.memory,memory.total,memory.free,memory.used --format=csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJOVtX_NuEA3",
        "colab_type": "text"
      },
      "source": [
        "### Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eI_LdIAuGFV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cpkt = tf.train.Checkpoint(model=model)\n",
        "cpkt.restore(f\"{datadir}/some_path/model_cpkt-1\").assert_consumed()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NT2UMXOZuY4p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result=model.predict_generator(ds, verbose = 1 if verbose else 0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkIgBtoIua2p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.savez_compressed('some_file.npz',\n",
        "                    **dict(zip(['uniqe_id','start_logits','end_logits','answer_type_logits'],\n",
        "                               result)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3s7hVDYvL-I",
        "colab_type": "text"
      },
      "source": [
        "#### Creating a DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qux93i9pvFUQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_answers_df = pd.read_json(f\"{outdir}/predictions.json\")\n",
        "\n",
        "test_answers_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLhi7tgDvRVH",
        "colab_type": "text"
      },
      "source": [
        "### Generating the Submission File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T62_ONnivUfY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_submission = pd.read_csv(f\"{datadir}/{competition}/sample_submission.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEDab0LOvYXg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_submission.to_csv(f\"{outdir}/submission.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPLARC3bvbyi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_submission.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akKwcXNnJvi2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! zdump PST\n",
        "if verbose:\n",
        "    ! pwd\n",
        "    list_files(basedir)\n",
        "! ls -l {outdir}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzrMC-QqvR99",
        "colab_type": "text"
      },
      "source": [
        "# Cells below this need to be deleted before submitting Notebook to competition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmkZDNQK98df",
        "colab_type": "text"
      },
      "source": [
        "## -- Submitting Results --"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKE9TaFxJx1P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raise ExecutionStop(\"Don't let run all go beyond this\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYwGNnso97Yr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "## View Previous Results you have submitted\n",
        "#kaggle competitions list\n",
        "kaggle competitions submissions -c {competition}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rr1JY__B-PnG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Make Submission\n",
        "# You may be able to submit to some competitions through the API\n",
        "! kaggle competitions submit -c {competition}} -f $RESULT_CSV  -m 'test kaggle cli 3'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBJjB1J3-fUL",
        "colab_type": "text"
      },
      "source": [
        "Verify submission by viewing previous results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYcisyyw1TRw",
        "colab_type": "text"
      },
      "source": [
        "End of Project Notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Udo19R6y9LD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make sure user does not accedentially execute beyond end\n",
        "raise ExecutionStop(\"Stopping execution\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lRKAhZK8yvO_"
      },
      "source": [
        "# ====== Please fold this stuff up and ignore ====="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "r_TVSYoeyvPa"
      },
      "source": [
        "### SSH Setup\n",
        "This is only neeeded if you want to log into the Colab machine. Otherwise fold it up and ignore.<br>\n",
        "To use it you have to create a login at https://ngrok.com\n",
        "<Details>Thanks to Imad El Hanafi (https://imadelhanafi.com) for showing me how to do this.<p>\n",
        "You will need to create a free account at https://ngrok.com/ for the SSH tunnel to work.</Details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4xz3goHaB8n",
        "colab_type": "text"
      },
      "source": [
        "File paths are hard coded here because this may be run before program variables are established."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36OI5-u2u24e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## if you want to use the Kaggle api from command line you will need a kaggle.json file\n",
        "from pathlib import Path\n",
        "if Path('/content/gdrive/My Drive/colab/kaggle.json').exists() or \\\n",
        "                                    Path('/content/kaggle.json').exists():\n",
        "    pass    # we found a kaggle.json file\n",
        "else:\n",
        "    # Give user opportunity to upload a kaggle.json file\n",
        "    from google.colab import files\n",
        "    print('Upload kaggle.json if you want the Kaggle API to be availabel in bash.')\n",
        "    # The files.upload() command is failing sporatically with:\n",
        "    #   TypeError: Cannot read property '_uploadFiles' of undefined (just run this cell again)\n",
        "    ! rm \"/content/kaggle.json\"  2> /dev/null\n",
        "    files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y0NMPj1fyvPb",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "## Install sshd; Set to allow login and config\n",
        "apt-get install -o=Dpkg::Use-Pty=0 openssh-server pwgen > /dev/null\n",
        "mkdir -p /var/run/sshd\n",
        "echo \"PermitRootLogin yes\" >> /etc/ssh/sshd_config\n",
        "echo \"PasswordAuthentication yes\" >> /etc/ssh/sshd_config\n",
        "\n",
        "# set host key to known value (need to test if exist)\n",
        "! gdown -O \"/etc/ssh/ssh_host_rsa_key\" --id 17Vp-rLM0kLVsIqxo7GkV3YXibGCJ7WCR\n",
        "! gdown -O \"/etc/ssh/ssh_host_rsa_key.pub\" --id 1-5yW1EwMdBN0YlRe7McmwDxzmGyvq-gW\n",
        "# get script to modify login shell to match env of Notebook\n",
        "! gdown -O \"/root/init_shell.sh\" --id 1-9s5wuq5TkebgKbFvBYy4EeM8c2Ee0xc\n",
        "\n",
        "# this script will give fix the login shell so Python will work\n",
        "if [ -f \"/root/init_shell.sh\" ]; then\n",
        "    echo \"source /root/init_shell.sh\" >> /root/.bashrc\n",
        "fi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S1mmJ__lyvPh",
        "colab": {}
      },
      "source": [
        "## setup ssh user / pass and start sshd\n",
        "\n",
        "#Generate a random root password\n",
        "import random, string\n",
        "sshpass = ''.join(random.choice(string.ascii_letters + string.digits) for i in range(30))\n",
        "\n",
        "#Set root password\n",
        "! echo root:$sshpass | chpasswd\n",
        "\n",
        "#Run sshd\n",
        "get_ipython().system_raw('/usr/sbin/sshd -D &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "edJ3pW6YyvPl",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "## Get Ngrok from gdrive or try to download (see: https://ngrok.com/download)\n",
        "if [ -f \"/content/bertqa/colab/ngrok-stable-linux-amd64.zip\" ]; then\n",
        "    cp \"/content/bertqa/colab/ngrok-stable-linux-amd64.zip\" .\n",
        "    echo \"Using ngrok-stable-linux-amd64.zip from gdrive\"\n",
        "else\n",
        "    wget -q -c -nc https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "fi\n",
        "unzip -qq -n ngrok-stable-linux-amd64.zip\n",
        "rm ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YR0N4Iw8yvPq",
        "colab": {}
      },
      "source": [
        "## Get user to enter auth token from ngrok and start tunnel\n",
        "\n",
        "# Get token from ngrok for the tunnel\n",
        "print(\"Get your authtoken from https://dashboard.ngrok.com/auth\")\n",
        "import getpass\n",
        "authtoken = getpass.getpass()\n",
        "\n",
        "#Create tunnel\n",
        "get_ipython().system_raw('./ngrok authtoken $authtoken && ./ngrok tcp 22 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1VjsRvCTyvPt"
      },
      "source": [
        "#### ==============================<br>|====&nbsp;&nbsp;  SSH Login Credentials &nbsp;&nbsp;====||<br>=============================="
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "cellView": "both",
        "id": "WKjt0Wh0yvPv",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "print(\"username: root\")\n",
        "print(\"password: \", sshpass)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7OlwbxpWyvPz"
      },
      "source": [
        "Get the host name and port number at: https://dashboard.ngrok.com/status\n",
        "\n",
        "```bash\n",
        "ssh root@0.tcp.ngrok.io -p [ngrok_port]\n",
        "Login as: root\n",
        "Servrer refused our key\n",
        "root@0.tcp.ngrok.io's password: [see above]\n",
        "\n",
        "(Colab):/content$\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bjJcssgxyvP0"
      },
      "source": [
        "Install vim"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "euzlUBHLyvP1",
        "colab": {}
      },
      "source": [
        "! apt-get install vim > /dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ugtt5PxzyvP3"
      },
      "source": [
        "If you need to kill Ngrok run this cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CiP9qYfgyvP4",
        "colab": {}
      },
      "source": [
        "if False:\n",
        "    !kill $(ps aux | grep './ngrok' | awk '{print $2}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "n3MP_pJ5yvP5"
      },
      "source": [
        "## -- Misc Notes --"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cm6ErVGkyvP6"
      },
      "source": [
        "### Prevent Disconnects\n",
        "Colab periodically disconnects the browser.<br>\n",
        "You have to save model checkpoints to Google Drive so you don't lose work<br>\n",
        "See: https://mc.ai/google-colab-drive-as-persistent-storage-for-long-training-runs/<br>\n",
        "Something to try...<br>\n",
        "Ctrl+Shift+i in browser and in console run this code...\n",
        "```\n",
        "function KeepAlive(){\n",
        "    console.log(\"Maintaining Connection\");\n",
        "    document.querySelector(\"colab-toolbar-button#connect\").click()\n",
        "}\n",
        "setInterval(KeepAlive,60000);\n",
        "```\n",
        "There have been reports of people having their GPU privileges suspended for letting processes run for over 12 hours. It seems that they may penalize you rather than just cutting you off."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enrv0jdCyzCY",
        "colab_type": "text"
      },
      "source": [
        "### Monitor GPU\n",
        "```\n",
        "# From cli I think to monitor GPU while fiting\n",
        "$ nvidia-smi dmon\n",
        "$ nvidia-smi pmon\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5B7tvshjsgs",
        "colab_type": "text"
      },
      "source": [
        "### Code From Elsewhere"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpTRsZHmzZcA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi -i 0 -q -d MEMORY,UTILIZATION,POWER,CLOCK,COMPUTE"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}