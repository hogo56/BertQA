{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ColabGettingStarted.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "93AfEfEABMXB",
        "javRwDS6zhOC",
        "Vk7GFxxMNKej"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/howardgoff/BertQA/blob/master/ColabGettingStarted.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Js7aj8RDhSjz",
        "colab_type": "text"
      },
      "source": [
        "# Colab / Kaggle Getting Started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SA1MAb09BlQB",
        "colab_type": "text"
      },
      "source": [
        "I prefer to do my primary development in a Colab virtual machine but, competitions require your kernel to run on Kaggle for scoring. You can start with this notebook and add your own project code which should run in either location if you use the directory variables for file locations and correctly configure data and user libraries in Kaggle.<p>\n",
        "The main differences are the file locations. On Colab you will symlink to a google Drive and for Kaggle you will need to upload your files as a .zip data file If you want SSH access there is code at bottom to allow this for Colab (not possible on Kaggle).<p>\n",
        "If you run into problems or have suggestions I'd love to hear from you."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93AfEfEABMXB",
        "colab_type": "text"
      },
      "source": [
        "## Explanation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKO_K9DlBuyk",
        "colab_type": "text"
      },
      "source": [
        "### Data & Directories\n",
        "There are a couple of differences between Kaggle and Colab.<p>\n",
        "**Colab** - Is a live linux system with nothing being persistant. You can attach a google drive to your kernel and/or download files from gs://, GitHub, Kaggle, etc. Using drive can have a performance penalty but is the easiest way to access persistent files.<br>\n",
        "I am symlinking Library files and output files.<br>\n",
        "Because my google drive space is limited I choose to download large data files each time the kernel is used.<p>\n",
        "**Kaggle** - The kernel has a persistent ./input directory for data that is read only. You can attach data and library files there. (zip your files into a single file and upload the .zip).<br>\n",
        "Your private ./lib directory can ba zipped and uploaded there as ./input/lib<br>\n",
        "You can also create notebooks of kernel type \"script\" and then file->Add Utility Script in your competition notebook to attach the script files under ./usr/lib but you have to do this one file at a time. (see: https://www.kaggle.com/product-feedback/91185 for more information)<br>\n",
        "I don't think competition scoring allows internet access so all files have to be attached to your notebook at submit time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7d1DROZB3cF",
        "colab_type": "text"
      },
      "source": [
        "### User Libraries\n",
        "**Colab** - you have a file system you can write to and if you need libraries you download them from somewhere. (eg. Google Dirve, Kaggle, GitHub)<br>\n",
        "**Kaggle** - you have two options (internet connections are disabled during competition scoring):<p>\n",
        "   * Add custom libraries to a dataset and include the dataset in your Kaggle kernel.<br>\n",
        "   * Create a new kernel as a script, set it as a \"Utility Script\", add the kernel-script as a utility script in your competition kernel. The sctript will be linked to your kernel in the/kaggle/usr/lib directory (see: https://www.kaggle.com/product-feedback/91185 for more information) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jVUDqVnqy9-",
        "colab_type": "text"
      },
      "source": [
        "### SSH\n",
        "You can SSH into the Colab. If you do this you can vim the ./lib files directly and they will be\n",
        "persistant. Also, since all project and notebook ./lib files are in gdrive you can access all of them through any of your Colab kernels by using the gdrive directory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOQz9QFOB5EB",
        "colab_type": "text"
      },
      "source": [
        "### Switching between Colab & Kaggle\n",
        "One way of moving your script from Colab to Kaggle to run is:<br>\n",
        "   * delete all cells from your Kaggle competition notebook<br>\n",
        "   * download the .ipynb from Colab<br>\n",
        "   * upload it into the blank Kaggle notebook.<br>\n",
        "   * delete the cells near the bottom of the notebook that need to be deleted when running on Kaggle<br>\n",
        "   * update any script parameters (eg. verbose)\n",
        "   * zip your current library files into a lib.zip and upload to your Kaggle dataset file\n",
        "   * if you have changed ./data files make sure your Kaggle kernel has the current versions of those files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dMWt8F8B9k2",
        "colab_type": "text"
      },
      "source": [
        "### Drectory Structure (Notebook)\n",
        "\n",
        "* Kaggle &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <em>(cwd = /kaggle/working/)</em><br>\n",
        "  {datadir} = /kaggle/input<br>\n",
        "  {libdir} = /kaggle/input/lib &nbsp; &nbsp; &nbsp; (or /kaggle/usr/lib)<br>\n",
        "  {outdir} = /kaggle/working<br>\n",
        "* Colab &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <em>(cwd = /content/)</em><br>\n",
        "  {datadir} = /content/data<br>\n",
        "  {libdir} = /content/lib<br>\n",
        "  {outdir} = /content/output<br>\n",
        "\n",
        "#### - Required Libraries\n",
        "   * {libdir}/lib_names.py\n",
        "\n",
        "#### - Inputs (competition data)\n",
        "   * {datadir}/{competition}/ (from: https://www.kaggle.com/_path_/)\n",
        "\n",
        "#### - Required Data (additional packages)\n",
        "   * {datadir}/kaggle-dataset (from https://www.kaggle.com/_user_/_dataset_/)\n",
        "\n",
        "#### - Outputs\n",
        "   * {outdir}/predictions.json\n",
        "   * {outdir}/submission.csv<br>\n",
        "   * {outdir}/eval.tf_record<br>\n",
        "   * {outdir}/.ipynb_checkpoints/<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftZ8SR0WC5Nj",
        "colab_type": "text"
      },
      "source": [
        "### Drectory Structure (Google Drive)\n",
        "The following is the file structure for your google drive:<p>\n",
        "\n",
        "/My Drive/Colab/ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <em>(this directory should be private)</em><br>\n",
        "/My Drive/Colab/kaggle.json &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <em>(your personal Kaggle auth file)</em><br>\n",
        "/My Drive/Colab/{projdir}/ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; (folder for a specific project/competition)<br>\n",
        "/My Drive/Colab/{projdir}/{notebook}/&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;(individual notebook within project)<br>\n",
        "/My Drive/Colab/{projdir}/{notebook}/notebook.ipynb<br>\n",
        "/My Drive/Colab/{projdir}/{notebook}/lib/<br>\n",
        "/My Drive/Colab/{projdir}/{notebook}/output/<br>\n",
        "/My Drive/{projdir}/ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <em>(optional directory to be shared between teams)</em><br><p>\n",
        "Using this directory structure and the variables in the config variables section below you can have any number of projects on your google drive and any number of notebook versions in each project. Each notebook can have a unique set of libraries.<p>\n",
        "There is also a {nbver} which, if not '' is appended to the end of {outdir} and {libdir} offering additional flexibility if you want (if not just set it to ''}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfDEb-Lprdn2",
        "colab_type": "text"
      },
      "source": [
        "### GitHub\n",
        "As I learn more about GitHub I will add information here. But, I think you can choose to make repositaries out of either /My Drive/Colab/{projdir}/ or /My Drive/Colab/{projdir}/{notebook}/   <p>\n",
        "You can then either pull/push to the shared repo directly from the Colab (using ssh, using %%bash commands in notebook or by linking the google Drive to your local machine and doing it from there.<p>\n",
        "From within the Colab all files are in your google drive from the path /content/gdrive/My\\ Drive/Colab/..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiQT_p1OCN9J",
        "colab_type": "text"
      },
      "source": [
        "### - Notes\n",
        "Put notes about your Notebook here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jCycAU1aL99h"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### - Credits / Ancestry\n",
        "If your notebook is a fork or combination of other notebooks here you should provide links so other people can look at where you built your current work from.<p>\n",
        "This notebook is a fork of [mmmarchetti's notebook](https://www.kaggle.com/mmmarchetti/tensorflow-2-0-bert-yes-no-answers) which was a fork of [prokaj's - bert joint baseline notebook](https://www.kaggle.com/prokaj/bert-joint-baseline-notebook/notebook).<br>\n",
        "mmmarchetti made some modifications to slightly improve the code and get the YES / NO answers and leave the unknowns blank."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNoEkLc0CXXu",
        "colab_type": "text"
      },
      "source": [
        "## Notebook Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l37smAnmsG07",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CompSubmission = False                       # Set to True if submitting to Competition"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJDucp7Ttabs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Turn this on for development to make sure library updates get reimported\n",
        "#  will reduce performance so comment out for production.\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaUs7DxSKDVG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Helper Functions   (probably will move to a library eventually)\n",
        "import os\n",
        "\n",
        "# Custom Error Handler\n",
        "class ExecutionStop(Exception):\n",
        "    ''' forces notebook to stop with a raised exception '''\n",
        "    def __init__(self, value): self.value=value\n",
        "    def __str__(self): return(str(self.value))\n",
        "\n",
        "#  Show list of file sand directories                 (it seems that this is skipping the symlinks)\n",
        "def list_files(startpath, exclude=[\"/.config\", \"/gdrive\"]):\n",
        "    ''' Lists files in {startpath} optionally excluding {exclude} directories '''\n",
        "    for root, _, files in os.walk(startpath, followlinks=True):\n",
        "        if any([e in root for e in exclude]):\n",
        "            continue\n",
        "        level = root.replace(startpath, '').count(os.sep)\n",
        "        indent = ' ' * 4 * (level)\n",
        "        print(f\"{indent}{os.path.basename(root)}/\")\n",
        "        subindent = ' ' * 4 * (level + 1)\n",
        "        for f in files:\n",
        "            print(f\"{subindent}{f}\")\n",
        "\n",
        "def print_flags():\n",
        "    ''' Prints the program config flags '''\n",
        "    if verbose:\n",
        "        print(\"\\nParameters:\")\n",
        "        FLAGS = tf.flags.FLAGS\n",
        "        for attr, obj in sorted(FLAGS.__flags.items()):\n",
        "            print(f\"{attr.upper()}={obj.value}\")\n",
        "        print(\"\")\n",
        "\n",
        "def del_all_flags(FLAGS):\n",
        "    ''' Deletes all program flags '''\n",
        "    flags_dict = FLAGS._flags()\n",
        "    keys_list = [keys for keys in flags_dict]\n",
        "    for keys in keys_list:\n",
        "        FLAGS.__delattr__(keys)\n",
        "\n",
        "# raise ExecutionStop(\"Message\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F30YID4j_khp",
        "colab_type": "code",
        "outputId": "75b4ff90-bef1-4bc9-e856-b9b38feaa2fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "## Set file locations    (these variables are not implemented in the FLAGS code yet)\n",
        "import os, sys\n",
        "from pathlib import Path\n",
        "\n",
        "## Config Variables\n",
        "verbose = True if not CompSubmission else False  # Turn this off to supress some of the \"fyi\" output\n",
        "competition = 'kaggle-competition_data'          # make this the name of the Kaggle comp dataset\n",
        "train_file = ''                       # Set this below when you download the training file\n",
        "test_file = ''                        # Set this below when you download the test file\n",
        "projdir = 'projdir'                   # The project directory on Drive for this competition\n",
        "notebook = 'GettingStarted'           # Subdir on Drive for files specific to this notebook\n",
        "nbver = ''                            # library/output subfolder for this notebook version, or ''\n",
        "DownloadBigFiles = True               # Files will not download if already on drive\n",
        "EnableSMSMessages = False             # Allows notebook to attempt to send SMS alerts\n",
        "\n",
        "if Path('/content').exists():\n",
        "    print(\"Detected running on Colab\")\n",
        "    kernel = 'Colab'\n",
        "    basedir = '/content'\n",
        "    libdir = f\"{basedir}/lib\"\n",
        "    datadir = f\"{basedir}/data\"\n",
        "    outdir = f\"{basedir}/output\"      # will be symlinked to a user's private gdrive for persistence\n",
        "elif Path('/kaggle').exists():\n",
        "    print(\"Detected running on Kaggle\")\n",
        "    kernel = 'Kaggle'\n",
        "    basedir = '/kaggle'\n",
        "    libdir = f\"{basedir}/input/lib\"   # you will upload a {name}.zip file as a dataset\n",
        "    datadir = f\"{basedir}/input\"      # this may need to be '../input' for scoring\n",
        "    outdir = f\"{basedir}/working\"     # this may need to be '.' for scoring\n",
        "else:\n",
        "    raise ExecutionStop(\"Cannot continue without determining file locations\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Detected running on Colab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNzAuLZDzG_R",
        "colab_type": "text"
      },
      "source": [
        "# ============= Machine Spinup ============="
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKPv6ALYbXiY",
        "colab_type": "code",
        "outputId": "87ff3035-8a9d-45e0-95af-9187118c9225",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "! zdump PST\n",
        "if verbose:\n",
        "    list_files(basedir)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PST  Thu Jan 16 12:58:30 2020 PST\n",
            "content/\n",
            "    sample_data/\n",
            "        README.md\n",
            "        anscombe.json\n",
            "        california_housing_test.csv\n",
            "        mnist_test.csv\n",
            "        mnist_train_small.csv\n",
            "        california_housing_train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aheaRzVE6fs1",
        "colab_type": "text"
      },
      "source": [
        "## -- Setup --"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gixU6_gv678n",
        "colab_type": "text"
      },
      "source": [
        "### Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auXx45x70Qcs",
        "colab_type": "code",
        "outputId": "b19f786a-d154-465a-f244-32deddb21381",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        }
      },
      "source": [
        "## File link to Google Drive\n",
        "\n",
        "######\n",
        "##  WARNING: This is convienent but a rather bad idea from a security point of view. Mounting your\n",
        "##           Google Drive in this way makes your entire drive accessible read/write and then you\n",
        "##           are likely to run code from libraries that could be untrustable.\n",
        "##           Possible alternatives would be to use read only file sharing links or if you want\n",
        "##           read/write access (to allow file output for example) I would recommend creating a\n",
        "##           special Google Drive account that only has files related to your Colab work.\n",
        "######\n",
        "\n",
        "if kernel == 'Colab':\n",
        "    from google.colab import drive\n",
        "    drive.mount(f\"{basedir}/gdrive\", force_remount=False)   # true to reread drive\n",
        "\n",
        "    ## The file paths below will need to be adjusted and some folders/files will need to be \n",
        "    #  created on your gDrive to make the below mappings work.\n",
        "\n",
        "    # this is a link to a team shared google folder (if needed)\n",
        "    if False:\n",
        "        if Path(f\"{basedir}/{projdir}\").is_symlink():\n",
        "            ! rm \"{basedir}/{projdir}\"\n",
        "        ! ln -s \"{basedir}/gdrive/My Drive/{projdir}/\" \"{basedir}/{projdir}\"\n",
        "        if not Path(f\"{basedir}/{projdir}\").exists():\n",
        "            raise ExecutionStop(\"Symlink to shared project directory not found!\")\n",
        "\n",
        "    ## If you do not want to use the lib directoy from your Google Drive set this block False\n",
        "    if True:\n",
        "        if Path(libdir).is_symlink():\n",
        "            ! rm \"{libdir}\"\n",
        "        ! ln -s \"{basedir}/gdrive/My Drive/Colab/{projdir}/{notebook}/lib{nbver}/\" \"{libdir}\"\n",
        "        if not Path(libdir).exists():\n",
        "            raise ExecutionStop(\"Project libdir directory not found!\")\n",
        "\n",
        "    ## If you do not want output to be written to your Google Drive set this block False\n",
        "    if True:\n",
        "        if Path(outdir).is_symlink():\n",
        "            ! rm \"{outdir}\"\n",
        "        ! ln -s \"{basedir}/gdrive/My Drive/Colab/{projdir}/{notebook}/output{nbver}/\" \"{outdir}\"\n",
        "        if not Path(outdir).exists():\n",
        "            raise ExecutionStop(\"Project outdir directory not found!\")\n",
        "\n",
        "    ## If you want to use data from gDrive set to True, if False this will download data\n",
        "    #  To increase performance we are copying the data to locations on the VM\n",
        "    #  Adjust file names/locations as needed for your project\n",
        "    if False:\n",
        "        altdatasrc = f\"{basedir}/gdrive/My Drive/Colab/{projdir}/data\"\n",
        "        if not Path(f\"{altdatasrc}/compdata.flag\").exists():\n",
        "            if not Path(f\"{datadir}/compdata.flag\").exists():      ## Don't do anything if flag exists\n",
        "                print(\"\\nGetting Competition Data From Google Drive\")\n",
        "                ! [ -d \"{datadir}/{competition}\" ] || mkdir -p \"{datadir}/{competition}\"\n",
        "                ! cp \"{altdatasrc}/{competition}/sample_submission.csv\" \"{datadir}/{competition}/\"\n",
        "                ! cp \"{altdatasrc}/{competition}/simplified-nq-train.jsonl\" \"{datadir}/{competition}\"\n",
        "                ! cp \"{altdatasrc}/{competition}/simplified-nq-test.jsonl\" \"{datadir}/{competition}\"\n",
        "                ! cp \"{altdatasrc}/{competition}\"/*.tfrecords \"{datadir}/{competition}\"\n",
        "                ! touch \"{datadir}/compdata.flag\"\n",
        "                train_file = f\"{datadir}/{competition}/simplified-nq-train.jsonl\"\n",
        "                test_file = f\"{datadir}/{competition}/simplified-nq-test.jsonl\"\n",
        "        else:\n",
        "            raise ExecutionStop(\"Could not find compdata on Google Drive!\")\n",
        "\n",
        "        if not Path(f\"{altdatasrc}/bertfiles.flag\").exists():\n",
        "            if not Path(f\"{datadir}/bertfiles.flag\").exists():      ## Don't do anything if flag exists\n",
        "                print(\"Getting BERTjoint Model From Google Drive\")\n",
        "                ! [ -d \"{datadir}/bert-joint-baseline\" ] || mkdir -p \"{datadir}/bert-joint-baseline\"\n",
        "                ! cp \"{altdatasrc}/bert-joint-baseline\"/* \"{datadir}/bert-joint-baseline/\"\n",
        "                ! touch \"{datadir}/bertfiles.flag\"\n",
        "        else:\n",
        "            pass        # Getting bert data from Google is optional, it can be got later\n",
        "\n",
        "    if verbose:\n",
        "        print('\\n', basedir)\n",
        "        ! ls -lh \"{basedir}\""
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "\n",
            " /content\n",
            "total 12K\n",
            "drwx------ 4 root root 4.0K Jan 16 12:58 gdrive\n",
            "lrwxrwxrwx 1 root root   58 Jan 16 12:58 lib -> '/content/gdrive/My Drive/Colab/projdir/GettingStarted/lib/'\n",
            "lrwxrwxrwx 1 root root   61 Jan 16 12:58 output -> '/content/gdrive/My Drive/Colab/projdir/GettingStarted/output/'\n",
            "drwxr-xr-x 1 root root 4.0K Jan 13 16:38 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvKSjUFEVJ6i",
        "colab_type": "text"
      },
      "source": [
        "### SMS Messaging\n",
        "<Details>You will need an account with http://twillio.com for this to work and have copied your auth API token tnto a file on your google drive.<p>\n",
        "You will also need a json file with the following config information:<p>\n",
        "```\n",
        "{\n",
        "\"account_sid\":\"{your account_sid}\",\n",
        "\"auth_token\":\"{your auth_token}\",\n",
        "\"send_to\":\"+1{delivery number}\",\n",
        "\"send_from\":\"+1{your twilio number}\"\n",
        "}\n",
        "```\n",
        "</Details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbdR3jpaVdVY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if EnableSMSMessages and kernel == 'Colab':\n",
        "    ! pip3 install twilio > /dev/null\n",
        "    from twilio.rest import Client as TC\n",
        "    import json\n",
        "    twil_file = f\"{basedir}/gdrive/My Drive/Colab/twilio.json\" \n",
        "    if Path(twil_file).exists():\n",
        "        # if there is a twilio.json file in gdrive use it\n",
        "        with open(twil_file, 'r') as f:\n",
        "            twil_auth = json.load(f)\n",
        "\n",
        "        account_sid = twil_auth[\"account_sid\"]\n",
        "        auth_token  = twil_auth[\"auth_token\"]\n",
        "\n",
        "        sms = TC(account_sid, auth_token)\n",
        "    else:\n",
        "        sms = None\n",
        "else:\n",
        "    sms = None\n",
        "\n",
        "def sms_message(str_msg):\n",
        "    ''' Sends messages through sms gateway to notify user of alerts.\n",
        "        If not enabled calls to sms_message() will silently do nothing.\n",
        "        For this to work you need an account at https://www.twilio.com/\n",
        "        Config through a twilio.json file (called above) that must contains\n",
        "        {account_sid, auth_token, send_to, send_from}\n",
        "    '''\n",
        "    if sms is not None:\n",
        "        message = sms.messages.create(\n",
        "            to=twil_auth['send_to'], \n",
        "            from_=twil_auth['send_from'],\n",
        "            body=str_msg)\n",
        "        if message.error_message is not None:\n",
        "            print(f\"\\nSMS Error: {message.error_message}\")\n",
        "\n",
        "sms_message(\"Twilio SMS gateway from Colab enabled\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8BLJAW95ih-",
        "colab_type": "text"
      },
      "source": [
        "### Kaggle API\n",
        "<Details>You will need Kaggle API token to link the Colab instance to your Kaggle account to get data, etc.<br>\n",
        "Go to: https://www.kaggle.com/yourID/account and click on the \"Create New API Token: button to get a file named kaggle.json.<p>You can put your kaggle.json file in your google drive at My Drive/colab/kaggle.json.<br>\n",
        "Alternately, you can store it on your local machine and the script will ask you to upload it.</Details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lc3IYPUg17c8",
        "colab_type": "code",
        "outputId": "407b9770-ef82-4ef6-dca2-69979a049a3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "## Link to Kaggle\n",
        "if kernel == 'Colab':\n",
        "    from google.colab import files\n",
        "    if Path(f\"{basedir}/gdrive/My Drive/Colab/kaggle.json\").exists():\n",
        "        # if there is a kaggle.json file in gdrive use it\n",
        "        os.environ['KAGGLE_CONFIG_DIR'] = f\"{basedir}/gdrive/My Drive/Colab/\"\n",
        "        ! ls -lh \"{basedir}/gdrive/My Drive/Colab/kaggle.json\"\n",
        "    else:\n",
        "        # Have user upload file\n",
        "        print('Upload kaggle.json.')\n",
        "        # The files.upload() command is failing sporatically with:\n",
        "        #   TypeError: Cannot read property '_uploadFiles' of undefined (just run this cell again)\n",
        "        ! rm \"{basedir}/kaggle.json\"  2> /dev/null\n",
        "        files.upload()\n",
        "        ! chmod 600 kaggle.json\n",
        "        os.environ['KAGGLE_CONFIG_DIR'] = f\"{basedir}/\"\n",
        "        ! ls -lh \"{basedir}/kaggle.json\"\n",
        "    # import kaggle                           # gives us access to kaggle.api\n",
        "    # help(kaggle)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw------- 1 root root 66 Dec 15 08:31 '/content/gdrive/My Drive/Colab/kaggle.json'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0k60Je4YEQa",
        "colab_type": "text"
      },
      "source": [
        "## -- Main System Config --\n",
        "<Details><Summary>Global Config</Summary>\n",
        "Put any global system configuration here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72Ermuc261_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if kernel == \"Colab\":\n",
        "    if Path(f\"{basedir}/sample_data\").exists():\n",
        "        ! rm -rf \"{basedir}/sample_data\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNKoTizrh9RG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash -s \"{libdir}\" \"{datadir}\" \"{outdir}\"\n",
        "# make directories if not already exist\n",
        "[ -d \"$1\" ] || mkdir -p \"$1\"        # {libdir}\n",
        "[ -d \"$2\" ] || mkdir -p \"$2\"        # {datadir}\n",
        "[ -d \"$3\" ] || mkdir -p \"$3\"        # {outdir}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdjitRnQynwk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys, os\n",
        "if not libdir in sys.path:                       # don't add multiple times\n",
        "    sys.path.append(libdir)\n",
        "if not (libdir in os.environ['PYTHONPATH']):     # needed to run python scripts from shell\n",
        "    os.environ['PYTHONPATH'] += f\":{libdir}\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Pq9DBlECVVvY",
        "outputId": "adee6205-d32b-416e-bc00-2c409fa069b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        }
      },
      "source": [
        "if verbose:\n",
        "    !pwd\n",
        "    !ls -lh\n",
        "    print('', \"sys.path:\", *sys.path, '', sep='\\n')\n",
        "    !printenv |grep -E 'KAGGLE|PYTHON'\n",
        "    print()\n",
        "! zdump PST"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "total 12K\n",
            "drwxr-xr-x 2 root root 4.0K Jan 16 12:59 data\n",
            "drwx------ 4 root root 4.0K Jan 16 12:58 gdrive\n",
            "lrwxrwxrwx 1 root root   58 Jan 16 12:58 lib -> '/content/gdrive/My Drive/Colab/projdir/GettingStarted/lib/'\n",
            "lrwxrwxrwx 1 root root   61 Jan 16 12:58 output -> '/content/gdrive/My Drive/Colab/projdir/GettingStarted/output/'\n",
            "\n",
            "sys.path:\n",
            "\n",
            "/env/python\n",
            "/usr/lib/python36.zip\n",
            "/usr/lib/python3.6\n",
            "/usr/lib/python3.6/lib-dynload\n",
            "/usr/local/lib/python3.6/dist-packages\n",
            "/usr/lib/python3/dist-packages\n",
            "/usr/local/lib/python3.6/dist-packages/IPython/extensions\n",
            "/root/.ipython\n",
            "/content/lib\n",
            "\n",
            "KAGGLE_CONFIG_DIR=/content/gdrive/My Drive/Colab/\n",
            "PYTHONWARNINGS=ignore:::pip._internal.cli.base_command\n",
            "PYTHONPATH=/env/python:/content/lib\n",
            "\n",
            "PST  Thu Jan 16 12:59:14 2020 PST\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "javRwDS6zhOC",
        "colab_type": "text"
      },
      "source": [
        "# =========== Project Specific Setup ==========="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAqCNh4y8DJz",
        "colab_type": "text"
      },
      "source": [
        "### Download Dataset and Support Files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGGM0EVmM24H",
        "colab_type": "text"
      },
      "source": [
        "Kaggle Competition Files<br>\n",
        "Here is an example of downlaoding and unpacking competition data. If the competition set has different files you will need to adjust."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5XcpPkyLBzaA",
        "outputId": "319ad18e-860c-4be3-ecfb-79efcf0df04e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        }
      },
      "source": [
        "## Competition Dataset  (5GB zipped)\n",
        "if DownloadBigFiles and kernel == 'Colab':\n",
        "    if not Path(f\"{datadir}/compdata.flag\").exists():      ## Don't download again if exists\n",
        "        ## comp data might exist from previous run or because you copied it from gDrive\n",
        "        #  Adjust file names as needed\n",
        "        print(\"Downloading Competition Data\\n\")\n",
        "        ! kaggle competitions download -c \"{competition}\" -p \"{datadir}\"\n",
        "        ! mkdir -p \"{datadir}/{competition}/\"\n",
        "        ! mv \"{datadir}/sample_submission.csv\"  \"{datadir}/{competition}\"\n",
        "        ! unzip \"{datadir}/simplified-nq-train.jsonl.zip\" -d \"{datadir}/{competition}\"\n",
        "        ! rm \"{datadir}/simplified-nq-train.jsonl.zip\"\n",
        "        ! unzip \"{datadir}/simplified-nq-test.jsonl.zip\" -d \"{datadir}/{competition}\"\n",
        "        ! rm \"{datadir}/simplified-nq-test.jsonl.zip\"\n",
        "        ! touch \"{datadir}/compdata.flag\"\n",
        "    else:\n",
        "        print(\"Competition Data already exists. Not downloading.\\n\")\n",
        "        !ls -lh \"{datadir}/{competition}\"/*\n",
        "    train_file = f\"{datadir}/{competition}/simplified-nq-train.jsonl\"\n",
        "    test_file = f\"{datadir}/{competition}/simplified-nq-test.jsonl\"\n",
        "else:\n",
        "    print(\"For Kaggle, make sure you download a copy of the competition data into your kernel\")\n",
        "    ! ls -lh \"{datadir}/{competition}\"/*\n",
        "    train_file = f\"{datadir}/{competition}/simplified-nq-train.jsonl\"\n",
        "    test_file = f\"{datadir}/{competition}/simplified-nq-test.jsonl\"\n",
        "\n",
        "    # public_dataset = os.path.getsize(f\"{test_file}\") < 20_000_000\n",
        "    # private_dataset = os.path.getsize(f\"{test_file}\") >= 20_000_000"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading Competition Data\n",
            "\n",
            "404 - Not Found\n",
            "mv: cannot stat '/content/data/sample_submission.csv': No such file or directory\n",
            "unzip:  cannot find or open /content/data/simplified-nq-train.jsonl.zip, /content/data/simplified-nq-train.jsonl.zip.zip or /content/data/simplified-nq-train.jsonl.zip.ZIP.\n",
            "rm: cannot remove '/content/data/simplified-nq-train.jsonl.zip': No such file or directory\n",
            "unzip:  cannot find or open /content/data/simplified-nq-test.jsonl.zip, /content/data/simplified-nq-test.jsonl.zip.zip or /content/data/simplified-nq-test.jsonl.zip.ZIP.\n",
            "rm: cannot remove '/content/data/simplified-nq-test.jsonl.zip': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZhNV3PJHOEL",
        "colab_type": "text"
      },
      "source": [
        "Additional Data Files<br>\n",
        "Here is an example of downlaoding and unpacking additional data files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s207mPqAHDVw",
        "colab_type": "code",
        "outputId": "58860878-8aea-4433-bf73-3585a7ca02da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        }
      },
      "source": [
        "## Get BERTjoint model files (this a copy of the prokaj file from my Google Drive)\n",
        "#  You will need to adjust file names and paths to get any required files for your project\n",
        "if DownloadBigFiles and kernel == 'Colab':\n",
        "    if not Path(f\"{datadir}/bertfiles.flag\").exists():      ## Don't download again if exists\n",
        "        print(\"Downloading BERT-joint Model\\n\")\n",
        "        ! mkdir -p \"{datadir}/bert-joint-baseline/\"\n",
        "        filestoget = \"bert_config* model_cpkt* nq-test* vocab*\"\n",
        "        ! kaggle datasets download -d prokaj/bert-joint-baseline -p \"{datadir}\"\n",
        "        ! unzip \"{datadir}/bert-joint-baseline.zip\" {filestoget} -d \"{datadir}/bert-joint-baseline/\"\n",
        "        ! rm \"{datadir}/bert-joint-baseline.zip\"\n",
        "        if Path(f\"{datadir}/bert-joint-baseline-output.npz\").exists():\n",
        "            ! rm \"{datadir}/bert-joint-baseline-output.npz\" # if kaggle downloaded this delete it\n",
        "        if verbose:\n",
        "            ! ls -lh \"{datadir}/bert-joint-baseline/\"\n",
        "        ! touch \"{datadir}/bertfiles.flag\"\n",
        "    else:\n",
        "        print(\"BERT-joint Files already exists. Not downloading.\\n\")\n",
        "        ! ls -lh \"{datadir}/bert-joint-baseline/\"\n",
        "else:\n",
        "    print(\"For Kaggle, make sure you download a copy of prokaj's bert-joint-baseline to your kernel\")\n",
        "    ! ls -lh \"{datadir}/bert-joint-baseline/\""
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading BERT-joint Model\n",
            "\n",
            "Downloading bert-joint-baseline.zip to /content/data\n",
            " 98% 1.51G/1.53G [00:36<00:00, 41.5MB/s]\n",
            "100% 1.53G/1.53G [00:36<00:00, 45.0MB/s]\n",
            "Archive:  /content/data/bert-joint-baseline.zip\n",
            "  inflating: /content/data/bert-joint-baseline/bert_config.json  \n",
            "  inflating: /content/data/bert-joint-baseline/model_cpkt-1.data-00000-of-00002  \n",
            "  inflating: /content/data/bert-joint-baseline/model_cpkt-1.data-00001-of-00002  \n",
            "  inflating: /content/data/bert-joint-baseline/model_cpkt-1.index  \n",
            "  inflating: /content/data/bert-joint-baseline/nq-test.tfrecords  \n",
            "  inflating: /content/data/bert-joint-baseline/vocab-nq.txt  \n",
            "total 1.3G\n",
            "-rw-r--r-- 1 root root  314 Nov 17 15:02 bert_config.json\n",
            "-rw-r--r-- 1 root root  78K Nov 17 15:02 model_cpkt-1.data-00000-of-00002\n",
            "-rw-r--r-- 1 root root 1.3G Nov 17 15:02 model_cpkt-1.data-00001-of-00002\n",
            "-rw-r--r-- 1 root root  29K Nov 17 15:05 model_cpkt-1.index\n",
            "-rw-r--r-- 1 root root  30M Nov 17 15:05 nq-test.tfrecords\n",
            "-rw-r--r-- 1 root root 227K Nov 17 15:06 vocab-nq.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bNPxSmhMJC5c"
      },
      "source": [
        "### Library Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T1jkYjB4XsDk"
      },
      "source": [
        "Custom libraries are uploaded to google Drive and symlinked if on Colab and zipped and<br>\n",
        "uploaded to a dataset if on Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yr69yF8fepTA",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "bb241a98-a736-4d6c-8139-5ec8e88ff185",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# if you need to move/copy any lib files to final locations do it here\n",
        "if kernel == 'Colab':\n",
        "    pass\n",
        "if kernel == 'Kaggle':\n",
        "    pass\n",
        "\n",
        "if verbose:\n",
        "    print(f\"{libdir}/\")\n",
        "    ! ls -lh \"{libdir}\"/*"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/lib/\n",
            "ls: cannot access '/content/lib/*': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhpBRp11R0jv",
        "colab_type": "code",
        "outputId": "726b692c-e9d1-4415-db20-326b1c492288",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "## Load Libraries\n",
        "import os, sys, importlib\n",
        "from pprint import pprint\n",
        "\n",
        "if kernel == \"Colab\":               # Kaggle is V2 by default\n",
        "    #magic to make Colab path to Tensorflow V2 on Colab\n",
        "    %tensorflow_version 2.x \n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras as tk\n",
        "from tensorflow.keras import layers as tkl\n",
        "print(\"TensofFlow\", tf.__version__)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import collections\n",
        "import json"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "TensofFlow 2.1.0-rc1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJC4o-hkuIfO",
        "colab_type": "code",
        "outputId": "bbcf0cd8-4748-4b40-8404-c4501236f1ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        }
      },
      "source": [
        "! zdump PST\n",
        "if verbose:\n",
        "    list_files(basedir)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PST  Thu Jan 16 13:00:42 2020 PST\n",
            "content/\n",
            "    data/\n",
            "        compdata.flag\n",
            "        bertfiles.flag\n",
            "        kaggle-competition_data/\n",
            "        bert-joint-baseline/\n",
            "            bert_config.json\n",
            "            model_cpkt-1.data-00000-of-00002\n",
            "            nq-test.tfrecords\n",
            "            model_cpkt-1.data-00001-of-00002\n",
            "            vocab-nq.txt\n",
            "            model_cpkt-1.index\n",
            "    lib/\n",
            "    output/\n",
            "        main_model_1.h5\n",
            "        main_model_2.h5\n",
            "        main_model_4.h5\n",
            "        main_model.h5\n",
            "        model_checkpoint.data-00001-of-00002\n",
            "        model_checkpoint.data-00000-of-00002\n",
            "        model_checkpoint.index\n",
            "        checkpoint\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7niWvRW-R5C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# raise ExecutionStop(\"Execution stopped\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1FG1uHaqwIz",
        "colab_type": "text"
      },
      "source": [
        "# =========== Project Code ==========="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNsu4BSzU3ZS",
        "colab_type": "text"
      },
      "source": [
        "Note: The Keras code here is not tuned or intended to create correct predictions.<br>\n",
        "It is just here to show the steps and syntax of a sample program."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLlkPPayNOi_",
        "colab_type": "text"
      },
      "source": [
        "## -- Load Data --"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bh16gCUI3pis",
        "colab_type": "text"
      },
      "source": [
        "Data can be delivered in a numpy array. In TF2, tf.data provides for loading and preprocesing data<br>\n",
        "in a way that is fast and scalable. see: https://www.tensorflow.org/guide/data  <font color='red'>\\<--Read This</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OGmnaKMh5Tm",
        "colab_type": "text"
      },
      "source": [
        "<Details><Summary>Data Label Description</Summary>\n",
        "<blockquote>\n",
        "            0\tT-shirt/top<br>\n",
        "            1\tTrouser<br>\n",
        "            2\tPullover<br>\n",
        "            3\tDress<br>\n",
        "            4\tCoat<br>\n",
        "            5\tSandal<br>\n",
        "            6\tShirt<br>\n",
        "            7\tSneaker<br>\n",
        "            8\tBag<br>\n",
        "            9\tAnkle boot<br>\n",
        "</blockquote>\n",
        "</Details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4o4qFt1QIfEi",
        "colab_type": "code",
        "outputId": "16c986b8-b566-4534-896e-e92a76b36188",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "## if your dataset is small and fits into memory you should use Numpy arrays or tf.data Datasets\n",
        "(X_train, y_train), (X_test, y_test) = tk.datasets.mnist.load_data()\n",
        "\n",
        "## Preprocess the data\n",
        "X_train = X_train.reshape(60000, 784).astype('float32') / 255\n",
        "X_test = X_test.reshape(10000, 784).astype('float32') / 255\n",
        "\n",
        "y_train = y_train.astype('float32')\n",
        "y_test = y_test.astype('float32')\n",
        "\n",
        "## You can tell fit to reserve a percentage of training data for validation or provide explicit \n",
        "#  validation data. If you use validation_split fit will take that percentage off the end of\n",
        "#  training data before shuffling it.\n",
        "X_val = X_train[-10000:]\n",
        "y_val = y_train[-10000:]\n",
        "X_train = X_train[:-10000]\n",
        "y_train = y_train[:-10000]\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGtTcPP3NTws",
        "colab_type": "text"
      },
      "source": [
        "# -- Define Model --"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrYNxFunNbUM",
        "colab_type": "code",
        "outputId": "15e084fc-b139-4657-dec8-c0649b9193c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 705
        }
      },
      "source": [
        "tk.backend.clear_session()     ## Reset Notebook\n",
        "\n",
        "## Define Layers\n",
        "inputs_1 = tk.Input(shape=(784,), name='digits')\n",
        "dense_1 = tkl.Dense(64, activation='relu', name='dense_1')(inputs_1)\n",
        "dense_2 = tkl.Dense(64, activation='relu', name='dense_2')(dense_1)\n",
        "outputs_1 = tkl.Dense(10, activation='softmax', name='predictions')(dense_2)\n",
        "\n",
        "## Define Model\n",
        "model = tk.Model(inputs=inputs_1, outputs=outputs_1, name='main_model')\n",
        "\n",
        "## Print informaiton about model\n",
        "model.summary()\n",
        "print()\n",
        "tk.utils.plot_model( model,\n",
        "                     to_file='main_model.png',\n",
        "                     show_shapes=True,\n",
        "                     show_layer_names = True,\n",
        "                     rankdir = 'TB',            # TB creates vertical; LR creates horizontal\n",
        "                     expand_nested = True,     # expand nested models into clusters\n",
        "                     dpi = 96\n",
        "                    )\n",
        "\n",
        "## To evaluate layers\n",
        "# layer.shape\n",
        "# layer.dtype\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"main_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "digits (InputLayer)          [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                50240     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 55,050\n",
            "Trainable params: 55,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVUAAAGVCAIAAADBhvXNAAAABmJLR0QA/wD/AP+gvaeTAAAgAElE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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gsFd-W5Nk-J",
        "colab_type": "text"
      },
      "source": [
        "## -- Compile Model --"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YOhDvfkaW0-",
        "colab_type": "text"
      },
      "source": [
        "<Details><Summary>Optimizer, Loss & Metric values</Summary>\n",
        "Supported optimizers: https://www.tensorflow.org/api_docs/python/tf/keras/optimizers\n",
        " * SGD() with or without momentum\n",
        " * RMSprop()\n",
        " * Adam()\n",
        "\n",
        "Supported loss functions: https://www.tensorflow.org/api_docs/python/tf/keras/losses\n",
        " * binary_crossentropy - binary classification\n",
        " * sparse_categorical_crossentropy - multi-class classification\n",
        " * mean_squared_error -  regression\n",
        " * cosine_similarity\n",
        " * you can define custom loss functions\n",
        "\n",
        "Supported metrics: https://www.tensorflow.org/api_docs/python/tf/keras/metrics\n",
        " * acu\n",
        " * precision\n",
        " * recall\n",
        "\n",
        " </Detail>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kc2pY8z9NqO2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## learning rate can be static, a schedule, or dynamic based on results\n",
        "learing_rate = 1e-3\n",
        "learning_rate = tk.optimizers.schedules.ExponentialDecay(\n",
        "                initial_learning_rate = 0.1,\n",
        "                decay_steps = 100000,\n",
        "                decay_rate = 0.96,\n",
        "                staircase = True\n",
        "               )\n",
        "\n",
        "model.compile( optimizer = tk.optimizers.RMSprop(learning_rate = learning_rate),\n",
        "               loss = 'sparse_categorical_crossentropy',\n",
        "               metrics = ['sparse_categorical_accuracy']\n",
        "              )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyY0ilH-NqYo",
        "colab_type": "text"
      },
      "source": [
        "# -- Fit Model -- "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hib3_LS_5vGF",
        "colab_type": "text"
      },
      "source": [
        "When you are training models on relatively large datasets it is crucial to save checkpoints of<br>\n",
        "your model at frequent intervals. The easiest way is to use the ModelCheckpoint callback."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTg3Z5cW587M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callbacks = [\n",
        "    tk.callbacks.ModelCheckpoint(\n",
        "        filepath = f\"{outdir}/\"+'main_model_{epoch}.h5',\n",
        "        monitor = 'val_loss',\n",
        "        save_best_only = True,          # overwrite current only if val_loss has improved\n",
        "        verbose = 1\n",
        "        ),\n",
        "    tk.callbacks.EarlyStopping(         ## Early stopping can prevent overfitting\n",
        "        monitor = 'val_loss',\n",
        "        #min_delta =,                   # change less than this will count as none\n",
        "        patience = 5,                   # number of epochs that produced no improvement\n",
        "        restore_best_weights = True     # go back to best values at end\n",
        "        )\n",
        "           ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZF_JzPncICo",
        "colab_type": "text"
      },
      "source": [
        "Train the model by slicing the data into \"batches\" of size batch_size, and repeatedly<br>\n",
        "iterating over the entire dataset for a given number of \"epochs\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mto880h3Nu5W",
        "colab_type": "code",
        "outputId": "14d6742f-5bcf-4f6c-c886-d5485780bb69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        }
      },
      "source": [
        "## you can also pass model.fit() validation_split rather than manually splitting the data set\n",
        "#  input can be a dict if model has named inputs\n",
        "history = model.fit( X_train,               # array/list of arrays (if model has multiple inputs)\n",
        "                     y_train,               # array/list of arrays (if model has multiple outputs)\n",
        "                     batch_size = 64,       # defaults to 32\n",
        "                     epochs = 5,\n",
        "                     shuffle = True,        # shuffles before each epoch\n",
        "                     # validation_split = 0.2,      # only works with numpy data\n",
        "                     validation_data = (X_val, y_val),\n",
        "                     validation_freq = 1,   # how many training epochs to run between validations\n",
        "                     callbacks = callbacks, # None or list of callbacks to apply\n",
        "                     # class_weight         # pay more attention to underrepresented classes\n",
        "                     # use_multiprocessing = False,\n",
        "                     # workers = 1,\n",
        "                     # max_queue_size       # used if input data is a sequence or generator\n",
        "                     verbose = 2            # 0 = off; 1 = progress bar; 2 = one line per epoch\n",
        "                    )\n",
        "\n",
        "print('\\nHistory Dict:')\n",
        "pprint(history.history)\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.80893, saving model to /content/output/main_model_1.h5\n",
            "50000/50000 - 5s - loss: 2.5223 - sparse_categorical_accuracy: 0.3260 - val_loss: 1.8089 - val_sparse_categorical_accuracy: 0.2818\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 1.80893\n",
            "50000/50000 - 2s - loss: 1.9050 - sparse_categorical_accuracy: 0.2859 - val_loss: 1.8354 - val_sparse_categorical_accuracy: 0.2169\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 1.80893\n",
            "50000/50000 - 2s - loss: 1.7522 - sparse_categorical_accuracy: 0.3254 - val_loss: 1.8269 - val_sparse_categorical_accuracy: 0.2894\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 1.80893\n",
            "50000/50000 - 2s - loss: 1.8806 - sparse_categorical_accuracy: 0.2781 - val_loss: 1.8707 - val_sparse_categorical_accuracy: 0.2781\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 1.80893\n",
            "50000/50000 - 2s - loss: 1.8473 - sparse_categorical_accuracy: 0.2864 - val_loss: 1.8248 - val_sparse_categorical_accuracy: 0.2544\n",
            "\n",
            "History Dict:\n",
            "{'loss': [2.5222665607452392,\n",
            "          1.904984670715332,\n",
            "          1.7521971371459961,\n",
            "          1.8806336560058594,\n",
            "          1.8473079159545898],\n",
            " 'sparse_categorical_accuracy': [0.326, 0.28588, 0.32544, 0.27806, 0.28636],\n",
            " 'val_loss': [1.808930484008789,\n",
            "              1.8354361289978027,\n",
            "              1.8268587291717528,\n",
            "              1.8707472305297852,\n",
            "              1.8248434175491333],\n",
            " 'val_sparse_categorical_accuracy': [0.2818, 0.2169, 0.2894, 0.2781, 0.2544]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3OEeKQpNvCP",
        "colab_type": "text"
      },
      "source": [
        " # -- Evaluate Model --"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETSTonO5N37M",
        "colab_type": "code",
        "outputId": "cfa87aa1-f475-41db-8a07-9b3af837955f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "loss, accuracy = model.evaluate( X_test,   # array or list of arrays (if model has multiple inputs)\n",
        "                                 y_test,   # array or list of arrays (if model has multiple outputs)\n",
        "                                 batch_size = 128,     # defaults to 32\n",
        "                                 callbacks = None,\n",
        "                                 # use_multiprocessing = False,\n",
        "                                 # workers = 1,\n",
        "                                 verbose = 1   # 0 = off; 1 = progress bar\n",
        "                                )\n",
        "\n",
        "print(f\"Test loss: {loss}\")\n",
        "print(f\"Test accuracy: {accuracy}\")\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 0s 18us/sample - loss: 1.8545 - sparse_categorical_accuracy: 0.2547\n",
            "Test loss: 1.8545054027557373\n",
            "Test accuracy: 0.2547000050544739\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slhVRKcwf_6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## -- Create Checkpoint --"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_DtPTMxgDZw",
        "colab_type": "text"
      },
      "source": [
        "Checkpoints capture the exact values of all parameters used by the model.<br>\n",
        "They do not contain any description of the computation defined by the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksXhlmnUgcOC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights(f\"{outdir}/model_checkpoint\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dS4jlUCdoybB",
        "colab_type": "text"
      },
      "source": [
        "## -- Save Model --"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVFDzYZe-ajv",
        "colab_type": "text"
      },
      "source": [
        "Saving a whole model (avaialble with simple and functional API models) you can recreate the model<br> later even if you do not have the code that created the model. The file includes: model architecture, model weight values; model training config; the optimizer and its state (if any) so you can restart training where you left off."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2HqM4Ufo4IE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model.predict(X_test)\n",
        "model.save(f\"{outdir}/model_save.h5\")\n",
        "del model\n",
        "\n",
        "# Recreate the exact same model purely from the save file\n",
        "model = tk.models.load_model(f\"{outdir}/model_save.h5\")\n",
        "new_predictions = model.predict(X_test)\n",
        "\n",
        "# verify that the predictions are the same\n",
        "np.testing.assert_allclose(predictions, new_predictions, rtol=1e-6, atol=1e-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFOnD7k9Cjvn",
        "colab_type": "text"
      },
      "source": [
        "Notes on saving other formats: https://www.tensorflow.org/guide/keras/save_and_serialize#export_to_savedmodel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Td3M6RzN4Sm",
        "colab_type": "text"
      },
      "source": [
        "# -- Make Predictions --"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97zE973KN7bE",
        "colab_type": "code",
        "outputId": "ee8fc975-a64f-49f3-bde4-3fe5aa47615b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "predictions = model.predict( X_test[:3],            # for now only predict on first 3\n",
        "                             batch_size = 32,       # defaults to 32\n",
        "                             callbacks = None,\n",
        "                             # use_multiprocessing = False,\n",
        "                             # workers = 1,\n",
        "                             verbose = 1            # 0 or 1\n",
        "                            )\n",
        "\n",
        "np.set_printoptions(suppress=True, precision=1)\n",
        "print(predictions)\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r3/3 [==============================] - 0s 873us/sample\n",
            "[[0.  0.  0.  0.  0.  0.  0.  1.  0.  0. ]\n",
            " [0.1 0.  0.2 0.1 0.  0.2 0.2 0.  0.1 0.1]\n",
            " [0.  0.2 0.1 0.  0.2 0.  0.  0.  0.  0.2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5BXA2hlwzJ-",
        "colab_type": "text"
      },
      "source": [
        "#&gt;&gt; Deleted to end before submitting to competition &lt;&lt;\n",
        "<Details> This is the end of the project notebook. The rest of this notebook is helpful for<br>\n",
        "development but should not be submitted to competition</Details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Udo19R6y9LD",
        "colab_type": "code",
        "outputId": "ac36b76f-29e2-426c-bea2-b07f3c07ff53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "# Make sure user does not accedentially execute beyond end\n",
        "raise ExecutionStop(\"Stopping execution\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ExecutionStop",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mExecutionStop\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-cced5245c4c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mExecutionStop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Stopping execution\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mExecutionStop\u001b[0m: Stopping execution"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lRKAhZK8yvO_"
      },
      "source": [
        "# ====== Development Support Files (safe to ignore) ====="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "r_TVSYoeyvPa"
      },
      "source": [
        "### SSH Setup\n",
        "This is only neeeded if you want to log into the Colab machine. Otherwise fold it up and ignore.<br>\n",
        "To use it you have to create a login at https://ngrok.com\n",
        "<Details>Thanks to Imad El Hanafi (https://imadelhanafi.com) for showing me how to do this.<p>\n",
        "You will need to create a free account at https://ngrok.com/ for the SSH tunnel to work.</Details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4xz3goHaB8n",
        "colab_type": "text"
      },
      "source": [
        "File paths are hard coded here because this may be run before program variables are established."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36OI5-u2u24e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## if you want to use the Kaggle api from command line you will need a kaggle.json file\n",
        "from pathlib import Path\n",
        "if Path('/content/gdrive/My Drive/Colab/kaggle.json').exists() or \\\n",
        "                                    Path('/content/kaggle.json').exists():\n",
        "    pass    # we found a kaggle.json file\n",
        "else:\n",
        "    # Give user opportunity to upload a kaggle.json file\n",
        "    from google.colab import files\n",
        "    print('Upload kaggle.json if you want the Kaggle API to be availabel in bash.')\n",
        "    # The files.upload() command is failing sporatically with:\n",
        "    #   TypeError: Cannot read property '_uploadFiles' of undefined (just run this cell again)\n",
        "    ! rm \"/content/kaggle.json\"  2> /dev/null\n",
        "    files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y0NMPj1fyvPb",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "## Install sshd; Set to allow login and config\n",
        "apt-get install -o=Dpkg::Use-Pty=0 openssh-server pwgen > /dev/null\n",
        "mkdir -p /var/run/sshd\n",
        "echo \"PermitRootLogin yes\" >> /etc/ssh/sshd_config\n",
        "echo \"PasswordAuthentication yes\" >> /etc/ssh/sshd_config\n",
        "\n",
        "# set host key to known value (need to test if exist)\n",
        "gdown -O \"/etc/ssh/ssh_host_rsa_key\" --id 17Vp-rLM0kLVsIqxo7GkV3YXibGCJ7WCR\n",
        "chown 600 \"/etc/ssh/ssh_host_rsa_key\"    # private key will be ignored if not secure\n",
        "gdown -O \"/etc/ssh/ssh_host_rsa_key.pub\" --id 1-5yW1EwMdBN0YlRe7McmwDxzmGyvq-gW\n",
        "# get script to modify login shell to match env of Notebook\n",
        "gdown -O \"/root/init_shell.sh\" --id 1-9s5wuq5TkebgKbFvBYy4EeM8c2Ee0xc\n",
        "\n",
        "# this script will give fix the login shell so Python will work\n",
        "if [ -f \"/root/init_shell.sh\" ]; then\n",
        "    echo \"source /root/init_shell.sh\" >> /root/.bashrc\n",
        "fi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S1mmJ__lyvPh",
        "colab": {}
      },
      "source": [
        "## setup ssh user / pass and start sshd\n",
        "\n",
        "#Generate a random root password\n",
        "import random, string\n",
        "sshpass = ''.join(random.choice(string.ascii_letters + string.digits) for i in range(30))\n",
        "\n",
        "#Set root password\n",
        "! echo root:$sshpass | chpasswd\n",
        "\n",
        "#Run sshd\n",
        "get_ipython().system_raw('/usr/sbin/sshd -D &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "edJ3pW6YyvPl",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "## Get Ngrok from gdrive or try to download (see: https://ngrok.com/download)\n",
        "if [ -f \"/content/bertqa/colab/ngrok-stable-linux-amd64.zip\" ]; then\n",
        "    cp \"/content/bertqa/colab/ngrok-stable-linux-amd64.zip\" .\n",
        "    echo \"Using ngrok-stable-linux-amd64.zip from gdrive\"\n",
        "else\n",
        "    wget -q -c -nc https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "fi\n",
        "unzip -qq -n ngrok-stable-linux-amd64.zip\n",
        "rm ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YR0N4Iw8yvPq",
        "colab": {}
      },
      "source": [
        "## Get user to enter auth token from ngrok and start tunnel\n",
        "\n",
        "# Get token from ngrok for the tunnel\n",
        "print(\"Get your authtoken from https://dashboard.ngrok.com/auth\")\n",
        "import getpass\n",
        "authtoken = getpass.getpass()\n",
        "\n",
        "#Create tunnel\n",
        "get_ipython().system_raw('./ngrok authtoken $authtoken && ./ngrok tcp 22 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1VjsRvCTyvPt"
      },
      "source": [
        "#### ===============================<br> ||====&nbsp;&nbsp;  SSH Login Credentials &nbsp;&nbsp;====||<br> ==============================="
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "cellView": "both",
        "id": "WKjt0Wh0yvPv",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "print(\"username: root\")\n",
        "print(\"password: \", sshpass)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7OlwbxpWyvPz"
      },
      "source": [
        "Get the host name and port number at: https://dashboard.ngrok.com/status\n",
        "\n",
        "```bash\n",
        "ssh root@0.tcp.ngrok.io -p [ngrok_port]\n",
        "Login as: root\n",
        "Servrer refused our key\n",
        "root@0.tcp.ngrok.io's password: [see above]\n",
        "\n",
        "(Colab):/content$\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bjJcssgxyvP0"
      },
      "source": [
        "Install programs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "euzlUBHLyvP1",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "# vim\n",
        "apt-get install vim > /dev/null\n",
        "echo \"set tabstop     =4\" >> ~/.vimrc\n",
        "echo \"set softtabstop =4\" >> ~/.vimrc\n",
        "echo \"set shiftwidth  =4\" >> ~/.vimrc\n",
        "echo \"set expandtab\"      >> ~/.vimrc\n",
        "\n",
        "# js is a JSON processor\n",
        "apt-get install js > /dev/null\n",
        "\n",
        "apt-get install tree > /dev/null\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ugtt5PxzyvP3"
      },
      "source": [
        "If you need to kill Ngrok run this cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CiP9qYfgyvP4",
        "colab": {}
      },
      "source": [
        "if False:\n",
        "    !kill $(ps aux | grep './ngrok' | awk '{print $2}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wz4Gpsh2AGEv",
        "colab_type": "text"
      },
      "source": [
        "Check out your GPU and RAM status"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ano8h810ADs0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# memory footprint support libraries/code\n",
        "! ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "! pip install gputil    > /dev/null\n",
        "! pip install psutil    > /dev/null\n",
        "! pip install humanize  > /dev/null\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "    process = psutil.Process(os.getpid())\n",
        "    print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "    print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "\n",
        "printm() # If your utilization is not 0% you are probably sharing with someone at the moment"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "n3MP_pJ5yvP5"
      },
      "source": [
        "## -- Misc Notes --"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cm6ErVGkyvP6"
      },
      "source": [
        "### Prevent Disconnects\n",
        "Colab periodically disconnects the browser.<br>\n",
        "You have to save model checkpoints to Google Drive so you don't lose work<br>\n",
        "See: https://mc.ai/google-colab-drive-as-persistent-storage-for-long-training-runs/<br>\n",
        "Something to try...<br>\n",
        "Ctrl+Shift+i in browser and in console run this code...\n",
        "```\n",
        "function KeepAlive(){\n",
        "    console.log(\"Maintaining Connection\");\n",
        "    document.querySelector(\"colab-toolbar-button#connect\").click()\n",
        "}\n",
        "setInterval(KeepAlive,60000);\n",
        "```\n",
        "There have been reports of people having their GPU privileges suspended for letting processes run for over 12 hours. It seems that they may penalize you rather than just cutting you off."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enrv0jdCyzCY",
        "colab_type": "text"
      },
      "source": [
        "### Monitor GPU\n",
        "```\n",
        "# From cli I think to monitor GPU while fiting\n",
        "$ nvidia-smi dmon\n",
        "$ nvidia-smi pmon\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5B7tvshjsgs",
        "colab_type": "text"
      },
      "source": [
        "### Code From Elsewhere"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbHIhd-POfaA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raise ExecutionStop(\"Stop Here\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpTRsZHmzZcA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi -i 0 -q -d MEMORY,UTILIZATION,POWER,CLOCK,COMPUTE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yHN7478zx5s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "## Convert notebook to HTML or PDF for printing\n",
        "\n",
        "### Clear All Output & Save Before Doing This ###\n",
        "\n",
        "apt-get install texlive texlive-xetex texlive-latex-extra mandoc > /dev/null\n",
        "pip install pypandoc\n",
        "# jupyter nbconvert --to HTML /content/gdrive/My\\ Drive/Colab/bertqa/BERTjoint_yes_no/BERTjoint\\ yes\\ no2.ipynb\n",
        "jupyter nbconvert --to HTML /content/gdrive/My\\ Drive/bertqa/BERTjoint_yes_no/BERTjoint\\ yes\\ no2.1.ipynb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vk7GFxxMNKej",
        "colab_type": "text"
      },
      "source": [
        "# ============ Notes / Eratta ============"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FYZK2heX5zC",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}