{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT for Humans Baseline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hogo56/BertQA/blob/master/BERT_for_Humans_Baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0k60Je4YEQa",
        "colab_type": "text"
      },
      "source": [
        "## --Main System Config--\n",
        "<Details>Put any global system configuration variables here</Details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eZox15QT-2T",
        "colab_type": "text"
      },
      "source": [
        "EnableAllCode - There are code blocks here that should not be run with \"Run All\". By default EnableAllCode will set to False and those blocks will be excluded. If you want to run them for some reason set EnableAllCode True.<p>\n",
        "The current setup code requires manual authentication to Google Drive and Kaggle so it cannot be run unattended."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNKoTizrh9RG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, sys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uw9zV9bwScZe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EnableAllCode = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1OMFCqATMSX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EnableAllCode = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aheaRzVE6fs1",
        "colab_type": "text"
      },
      "source": [
        "## -- Setup --"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5o6YuwIm1ni8",
        "colab_type": "text"
      },
      "source": [
        "If running for first time I would suggest Edit -> Clear All Outputs before starting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQGgsjkY0Rwh",
        "colab_type": "text"
      },
      "source": [
        "### Machine Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gixU6_gv678n",
        "colab_type": "text"
      },
      "source": [
        "--- Google Drive\n",
        "<Details>There are several ways to provide access to your Google Drive from Colab.<br>\n",
        "I am not sure if this is the best. This mounts your Drive into the machine.<br>\n",
        "I expect there will be a folder in the Drive that we all share.</Details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auXx45x70Qcs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## File link to Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=False)   # true to reread drive\n",
        "# Create a shorter shared directory name than one with a space\n",
        "! ln -s '/content/gdrive/My Drive/bertqa' /content/bertqa"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ga-sQOkk1YvA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if EnableAllCode:\n",
        "    ## Flush and unmount Google Drive\n",
        "    # You probablyu won't do this but if you want to at some point click the play button\n",
        "    drive.flush_and_unmount()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YfDRXH9NYmi3"
      },
      "source": [
        "### SSH Setup\n",
        "<Details> Shell access is not technically required but if you are like me and being able to look under the hood brings you comfort you can step throuth this.<br>\n",
        "Thanks to Imad El Hanafi (https://imadelhanafi.com) for showing me how to do this.</Details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zypzu9GdYmjH",
        "colab": {}
      },
      "source": [
        "# 1 - setup ssh/user \n",
        "\n",
        "#Generate a random root password\n",
        "import random, string\n",
        "sshpass = ''.join(random.choice(string.ascii_letters + string.digits) for i in range(30))\n",
        "\n",
        "#Setup sshd\n",
        "! apt-get install -qq -o=Dpkg::Use-Pty=0 openssh-server pwgen > /dev/null\n",
        "\n",
        "#Set root password\n",
        "! echo root:$sshpass | chpasswd\n",
        "! mkdir -p /var/run/sshd\n",
        "! echo \"PermitRootLogin yes\" >> /etc/ssh/sshd_config\n",
        "! echo \"PasswordAuthentication yes\" >> /etc/ssh/sshd_config\n",
        "\n",
        "print(\"username: root\")\n",
        "print(\"password: \", sshpass)\n",
        "\n",
        "#Run sshd\n",
        "get_ipython().system_raw('/usr/sbin/sshd -D &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wMqEbK_gYmjP",
        "colab": {}
      },
      "source": [
        "# 2 - Download Ngrok\n",
        "! wget -q -c -nc https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "! unzip -qq -n ngrok-stable-linux-amd64.zip\n",
        "! rm ngrok-stable-linux-amd64.zip\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4prYYUmadZm",
        "colab_type": "text"
      },
      "source": [
        "I think you will need to create a free account at https://ngrok.com/ for the SSH tunnel to work."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T3qqUMr8YmjX",
        "colab": {}
      },
      "source": [
        "# 3 - setup Ngrok - authtoken\n",
        "\n",
        "#Ask token\n",
        "print(\"Get your authtoken from https://dashboard.ngrok.com/auth\")\n",
        "import getpass\n",
        "authtoken = getpass.getpass()\n",
        "\n",
        "#Create tunnel\n",
        "get_ipython().system_raw('./ngrok authtoken $authtoken && ./ngrok tcp 22 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9I6mIU8nYmjb"
      },
      "source": [
        "Congratulations, you are ready to go. \n",
        "On Ngrok dashboard https://dashboard.ngrok.com/status you'll find the tcp address and the port you can connect to with your favorite ssh client. eg...\n",
        "\n",
        "```\n",
        "ssh root@0.tcp.ngrok.io -p [ngrok_port]\n",
        "> then enter the username and password shown from the codeblock above\n",
        "\n",
        "root@hostname:~ PS1=':\\w\\$ '\n",
        ":~# apt install vim\n",
        ":~# vim .bashrc        (if you want to change prompt PS1 there; also add cd/content to end)\n",
        ":~# cd /content\n",
        ":/content# ls -lh \n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_gkQz2BDYmjb",
        "colab": {}
      },
      "source": [
        "if EnableAllCode:\n",
        "    # When done, kill Ngrok\n",
        "    !kill $(ps aux | grep './ngrok' | awk '{print $2}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8BLJAW95ih-",
        "colab_type": "text"
      },
      "source": [
        "### Kaggle API\n",
        "<Details>You will need a token to link the Colab instance to the API of your Kaggle account to get data, etc.<br>\n",
        "Go to: https://www.kaggle.com/yourID/account and click on the \"Create New API Token: button to get a file named kattle.json and save it somewhere on your local drive.</Details>\n",
        "<Details><Summary>More...</Summary>I am choosing to upload the kaggle.json file from local hard drive each time. Alternately, we could put it in a private location on your gdrive (not the shared folder.)<br>\n",
        "If you want to use Drive, edit the location in the environ var so python knows where to find your kaggle.json file. By using a file upload however, the same code will work for everyone sharing this notebook</Details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lc3IYPUg17c8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Link to Kaggle\n",
        "# I am getting a sporatic error \"Cannot read property '_uploadFiles'\"; just retry and it works\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "!rm /content/kaggle.json\n",
        "print('Upload kaggle.json.')\n",
        "# You will need a kaggle auth file from your account\n",
        "uploaded = files.upload()\n",
        "!chmod 600 kaggle.json\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/\"\n",
        "!ls -l /content/kaggle.json\n",
        "\n",
        "import kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAqCNh4y8DJz",
        "colab_type": "text"
      },
      "source": [
        "Here is where you download the competition dataset. Only do this if you need it for your current work as it is 5GB (zipped)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UF-28Eb21E2w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p /content/data\n",
        "!mkdir -p /content/bert_output       # Maybe output to Google Drive for durability\n",
        "# Get Competition Data (5GB zipped)\n",
        "!kaggle competitions list\n",
        "!kaggle competitions download -c tensorflow2-question-answering -p /content/data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBdEiQTf6KCF",
        "colab_type": "text"
      },
      "source": [
        "### Library Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F18Sq3F35xtR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Fix Nvidia            (make sure your Runtime type is python3 + GPU)\n",
        "\n",
        "\"\"\" ToDo - Get Latest Nvidia Drivers \"\"\"\n",
        "if EnableAllCode:\n",
        "    # https://developer.nvidia.com/cudnn       (need to join developer program to get latest)\n",
        "\n",
        "    # Extracts the cuDNN files from Drive folder directly to the VM CUDA folders\n",
        "    !tar -xzvf bertqa/nvidia/cuDNN/cudnn-10.0-linux-x64-v7.5.0.56.tgz -C /usr/local/\n",
        "    !chmod a+r /usr/local/cuda/include/cudnn.h\n",
        "\n",
        "    # Now we check the version we already installed. Can comment this line on future runs\n",
        "    !cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yr69yF8fepTA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Setup local lib\n",
        "! mkdir /content/lib\n",
        "sys.path.append('/content/lib')\n",
        "! cp -a /content/bertqa/lib/* lib/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pdp6tqXmmLw_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get BERT   (https://www.kaggle.com/coolcoder22/colab-to-fine-tune-bert)\n",
        "! git clone https://github.com/google-research/bert.git\n",
        "\n",
        "# get pretrained models\n",
        "! wget https://storage.googleapis.com/bert_models/2018_10_18/cased_L-12_H-768_A-12.zip\n",
        "! unzip cased_L-12_H-768_A-12.zip\n",
        "! rm cased_L-12_H-768_A-12.zip\n",
        "! mv bert lib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oU6FPUHjvH1r",
        "colab_type": "text"
      },
      "source": [
        "Are these the correct bert models we are supposed to be using?<br>\n",
        "Maybe also look at https://github.com/tensorflow/models/tree/master/official/nlp/bert or,<br>\n",
        "https://github.com/google-research/language/tree/master/language/question_answering/bert_joint\n",
        "\n",
        "<Details><Summary>BERT Notes</Summary>\n",
        "baseline_w_bert_translated_to_tf2_0 (next code block) comes from /dimitreoliveira with this warning:<br>\n",
        "This baseline uses code that was migrated from TF1.x. Be aware that it contains use of tf.compat.v1, which is not permitted to be eligible for TF2.0 prizes in this competition. It is intended to be used as a starting point, but we're excited to see how much better you can do using TF2.0!<br>\n",
        "https://www.kaggle.com/dimitreoliveira/using-tf-2-0-w-bert-on-nq-translated-to-tf2-0</Details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhpBRp11R0jv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Load Libraries\n",
        "\n",
        "%tensorflow_version 2.x \n",
        "import tensorflow\n",
        "print(tensorflow.__version__)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "# import tf2_0_baseline_w_bert as tf2baseline # old script\n",
        "import tf2_0_baseline_w_bert_translated_to_tf2_0 as tf2baseline # Oliviera's script\n",
        "\n",
        "import bert.modeling as modeling\n",
        "import bert.optimization as optimization\n",
        "import bert.tokenization as tokenization\n",
        "\n",
        "import json\n",
        "import absl\n",
        "from zipfile import ZipFile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6zf1MNKGefD",
        "colab_type": "text"
      },
      "source": [
        "## --Explore Environment--\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzX2trD0GY5-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if EnableAllCode:\n",
        "    print('===== Python =====')\n",
        "    print('Version: ', sys.version)\n",
        "    ! pip -V\n",
        "    print('===== CPU Info =====')\n",
        "    !cat /proc/cpuinfo\n",
        "    print('\\n===== MEM Info =====')\n",
        "    !cat /proc/meminfo\n",
        "    print('\\n===== printenv =====')\n",
        "    ! printenv\n",
        "    from tensorflow.python.client import device_lib\n",
        "    print('\\n===== List Local Devices =====')\n",
        "    print(device_lib.list_local_devices())\n",
        "    print()\n",
        "    print(\"===== Dir of /:\", *(os.listdir('/')), sep='\\n')\n",
        "    print(\"\\n===== cwd: \", os.getcwd())                       # will be /content\n",
        "    print('\\n===== Files in', os.getcwd())\n",
        "    for dirname, _, filenames in os.walk(os.getcwd()):\n",
        "        for filename in filenames:\n",
        "            print(os.path.join(dirname, filename))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEo292sNysZ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if EnableAllCode:\n",
        "    print('\\n===== NVIDIA Info =====')\n",
        "    !nvidia-smi\n",
        "    print()\n",
        "    !/usr/local/cuda/bin/nvcc --version"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTGd9wM7VxHz",
        "colab_type": "text"
      },
      "source": [
        "## --Misc Notes--"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZzPMe0vWHdP",
        "colab_type": "text"
      },
      "source": [
        "### File Transfer to Local Machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4_3T1hiV_BI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## To upload files to Colab\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "print(uploaded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_ucQLj9V3kr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## To download files from Colab\n",
        "from google.colab import files\n",
        "model.save('trained_model.h5')          # but probably better to save directly to Drive\n",
        "files.download('trained_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBAZEpofWU1J",
        "colab_type": "text"
      },
      "source": [
        "### File Transfer from Web"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOzigjWWWYYn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from urllib.request import urlretrieve\n",
        "\n",
        "def download(url, file):\n",
        "    if not os.path.isfile(file):\n",
        "        print(\"Downloading file... \" + file + \" ...\")\n",
        "        urlretrieve(url,file)\n",
        "        print(\"File downloaded\")\n",
        "\n",
        "download('Url of the file','Name of the file to be saved')\n",
        "print(\"All the files are downloaded\")\n",
        "#If the downloaded file is a zip file than you can use below function to unzip it.\n",
        "def uncompress_features_labels(file):\n",
        "    if(os.path.isdir('data')):\n",
        "        print('Data extracted')\n",
        "    else:\n",
        "        with ZipFile(dir) as zipf:\n",
        "            zipf.extractall('data')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOGMBL7znY_5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! printenv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzADEFEdzHor",
        "colab_type": "text"
      },
      "source": [
        "### Prevent Disconnects\n",
        "Colab periodically disconnects the browser.<br>\n",
        "You have to save model checkpoints to Google Drive so you don't lose wor<br>\n",
        "See: https://mc.ai/google-colab-drive-as-persistent-storage-for-long-training-runs/<br>\n",
        "Something to try...<br>\n",
        "Ctrl+Shift+i in browser and in console run this code...\n",
        "```\n",
        "function KeepAlive(){\n",
        "    console.log(\"Maintaining Connection\");\n",
        "    document.querySelector(\"colab-toolbar-button#connect\").click()\n",
        "}\n",
        "setInterval(KeepAlive,60000);\n",
        "```\n",
        "There have been reports of people having their GPU privileges suspended for letting processes run for over 12 hours. It seems that they may penalize you rather than just cutting you off."
      ]
    }
  ]
}